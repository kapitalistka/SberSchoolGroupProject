{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ROZA GP2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Categorical Features\n",
        "\n",
        "Transaction\n",
        "ProductCD\n",
        "card1\n",
        "card6\n",
        "addr1, addr2\n",
        "P_emaildomain\n",
        "R_emaildomain\n",
        "M1 - M9\n",
        "\n",
        "*   Новый пункт\n",
        "*   Новый пункт\n",
        "*   Новый пункт\n",
        "*   Новый пункт\n",
        "*   Новый пункт\n",
        "*   Новый пункт\n",
        "*   Новый пункт\n",
        "*   Новый пункт\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Categorical Features\n",
        "\n",
        "Identity\n",
        "DeviceType\n",
        "DeviceInfo\n",
        "id_12 - id_38"
      ],
      "metadata": {
        "id": "ntzEqj1tjW9E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rujVvI7sfv6-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import datetime\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from  sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "telB4agcf_FK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры для данного ноутбука:"
      ],
      "metadata": {
        "id": "Wb7dPTPu7iAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'isFraud'\n",
        "is_drop_collinear = True # Удалять ли коррелирующие признаки\n",
        "coefficient_corr = 0.95 # Коэффициент корреляции, начиная с которого удалять признаки\n",
        "nan_percent = 0.95 # Степень незаполненности данных, при которой мы относим столбец к плохим\n",
        "is_drop_nan_columns = False # Удалять ли найденные признаки с плохой заполняемостью\n",
        "bad_fill_category_value = '_NAN_' # Чем заполнять пропуски в категориальных признаках\n",
        "bad_fill_float_value = 0 # Чем заполнять пропуски в вещественных признаках\n",
        "bad_fill_numeric_value = 0 # Чем заполнять пропуски в целочисленных признаках\n",
        "is_need_pca = False"
      ],
      "metadata": {
        "id": "-8CL9VJ-7qu2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем данные:"
      ],
      "metadata": {
        "id": "aDQgTifx9vTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "\"\"\"\n",
        "df_train_transaction = pd.read_csv('gdrive/My Drive/data/gp2/train_transaction.csv')\n",
        "df_train_transaction.head()\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Qw-z9D5IgEdg",
        "outputId": "e5c9d6d4-1be3-410e-ca18-e5b266efa2f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndf_train_transaction = pd.read_csv('gdrive/My Drive/data/gp2/train_transaction.csv')\\ndf_train_transaction.head()\""
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(transaction_csv, identity_csv,is_test = False):\n",
        "  df_train_transaction = pd.read_csv(transaction_csv)\n",
        "  df_train_identity = pd.read_csv(identity_csv)\n",
        "  df_train = df_train_transaction.merge(df_train_identity, how = 'left',on='TransactionID')\n",
        "  \n",
        "  del df_train_identity,df_train_transaction\n",
        "  gc.collect\n",
        "\n",
        "  if is_test == False:\n",
        "    df_y = pd.DataFrame(df_train[target])\n",
        "    df_train.drop(columns = [target],axis = 1, inplace = True)\n",
        "  else:\n",
        "    df_y = pd.DataFrame(df_train['TransactionID'])\n",
        "\n",
        "\n",
        "  df_train.drop('TransactionID', 1,inplace = True)\n",
        "  df_train.drop('TransactionDT', 1,inplace = True)\n",
        "  df_train.drop('DeviceType', 1,inplace = True)\n",
        "  df_train.drop('DeviceInfo', 1,inplace = True)\n",
        "\n",
        "  return df_train, df_y\n",
        "\n"
      ],
      "metadata": {
        "id": "xuP2FIWyTODm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_y = get_data('gdrive/My Drive/data/gp2/train_transaction.csv', \n",
        "                'gdrive/My Drive/data/gp2/train_identity.csv',\n",
        "                False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VXULpXlVnql",
        "outputId": "66bc6606-2ca0-43c8-c0cd-32a2487d6761"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"df_train_identity = pd.read_csv('gdrive/My Drive/data/gp2/train_identity.csv')\n",
        "df_train_identity.head()\"\"\"\""
      ],
      "metadata": {
        "id": "zl54vvhMgR9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объединим датасеты"
      ],
      "metadata": {
        "id": "gecyoaET52k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"print(df_train_transaction.shape,df_train_identity.shape)\n",
        "df_train = df_train_transaction.merge(df_train_identity, how = 'left',on='TransactionID')\n",
        "print(df_train.shape)\"\"\""
      ],
      "metadata": {
        "id": "uwNjLNf15vk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#del df_train_identity,df_train_transaction\n",
        "#gc.collect"
      ],
      "metadata": {
        "id": "bUwLXoyFPzfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выделим целевой признак:"
      ],
      "metadata": {
        "id": "34J6Wmnh_Rni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"df_train.drop('TransactionID', 1,inplace = True)\n",
        "df_train.drop('TransactionDT', 1,inplace = True)\n",
        "df_train.drop('DeviceType', 1,inplace = True)\n",
        "df_train.drop('DeviceInfo', 1,inplace = True)\"\"\""
      ],
      "metadata": {
        "id": "iyHCNvkXMv2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на корреляцию признаков"
      ],
      "metadata": {
        "id": "Ck2A_a3o3TjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_collinear_features(x, threshold=0.6):\n",
        "\n",
        "    \n",
        "    # Calculate the correlation matrix\n",
        "    corr_matrix = x.corr()\n",
        "    iters = range(len(corr_matrix.columns) - 1)\n",
        "    drop_cols = []\n",
        "\n",
        "    # Iterate through the correlation matrix and compare correlations\n",
        "    for i in iters:\n",
        "        for j in range(i):\n",
        "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
        "            col = item.columns\n",
        "            row = item.index\n",
        "            val = abs(item.values)\n",
        "            \n",
        "            # If correlation exceeds the threshold\n",
        "            if val >= threshold:\n",
        "                # Print the correlated features and the correlation value\n",
        "                print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
        "                drop_cols.append(col.values[0])\n",
        "\n",
        "    # Drop one of each pair of correlated columns\n",
        "    drops = set(drop_cols)\n",
        "    x = x.drop(columns = drops)\n",
        "    \n",
        "                   \n",
        "    return x"
      ],
      "metadata": {
        "id": "g-oxnE1Py4WP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if is_drop_collinear == True: \n",
        "  shape = df_train.shape[1]\n",
        "  df_trans = remove_collinear_features(df_train, coefficient_corr)\n",
        "  print('Удалено признаков:')\n",
        "  print(shape - df_trans.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj5bGdcm3R6d",
        "outputId": "7cb6d2b8-506d-445b-c9b3-f4f2ec228b01"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C4 | C1 | 0.97\n",
            "C4 | C2 | 0.97\n",
            "C6 | C1 | 0.98\n",
            "C6 | C2 | 0.97\n",
            "C6 | C4 | 0.96\n",
            "C8 | C1 | 0.97\n",
            "C8 | C2 | 0.98\n",
            "C8 | C4 | 0.96\n",
            "C10 | C1 | 0.96\n",
            "C10 | C2 | 0.97\n",
            "C10 | C4 | 0.95\n",
            "C10 | C7 | 0.99\n",
            "C10 | C8 | 1.0\n",
            "C11 | C1 | 1.0\n",
            "C11 | C2 | 0.99\n",
            "C11 | C4 | 0.97\n",
            "C11 | C6 | 0.99\n",
            "C11 | C8 | 0.96\n",
            "C12 | C7 | 1.0\n",
            "C12 | C8 | 0.98\n",
            "C12 | C10 | 0.98\n",
            "C14 | C1 | 0.95\n",
            "C14 | C6 | 0.98\n",
            "C14 | C11 | 0.96\n",
            "D6 | D4 | 0.96\n",
            "D7 | D5 | 0.99\n",
            "D12 | D4 | 1.0\n",
            "D12 | D6 | 0.98\n",
            "V21 | V17 | 0.95\n",
            "V33 | V15 | 0.96\n",
            "V50 | V31 | 0.98\n",
            "V50 | V32 | 0.96\n",
            "V57 | V15 | 0.96\n",
            "V63 | V42 | 0.95\n",
            "V71 | V31 | 0.96\n",
            "V71 | V50 | 0.96\n",
            "V84 | V21 | 0.96\n",
            "V84 | V42 | 0.96\n",
            "V84 | V63 | 0.96\n",
            "V89 | V28 | 0.97\n",
            "V92 | V31 | 0.97\n",
            "V92 | V50 | 0.97\n",
            "V92 | V71 | 0.96\n",
            "V94 | V15 | 0.95\n",
            "V94 | V33 | 0.98\n",
            "V94 | V51 | 0.95\n",
            "V101 | V95 | 1.0\n",
            "V102 | V96 | 1.0\n",
            "V102 | V97 | 0.99\n",
            "V103 | V96 | 0.99\n",
            "V103 | V97 | 1.0\n",
            "V126 | V95 | 0.98\n",
            "V126 | V101 | 0.98\n",
            "V127 | V96 | 0.99\n",
            "V127 | V97 | 0.98\n",
            "V127 | V102 | 0.99\n",
            "V127 | V103 | 0.98\n",
            "V128 | V96 | 0.98\n",
            "V128 | V97 | 0.99\n",
            "V128 | V102 | 0.98\n",
            "V128 | V103 | 0.99\n",
            "V132 | V95 | 1.0\n",
            "V132 | V101 | 1.0\n",
            "V132 | V126 | 0.99\n",
            "V133 | V96 | 0.99\n",
            "V133 | V97 | 0.98\n",
            "V133 | V102 | 1.0\n",
            "V133 | V103 | 0.99\n",
            "V133 | V127 | 0.99\n",
            "V133 | V128 | 0.98\n",
            "V134 | V96 | 0.99\n",
            "V134 | V97 | 0.99\n",
            "V134 | V102 | 0.99\n",
            "V134 | V103 | 1.0\n",
            "V134 | V127 | 0.99\n",
            "V134 | V128 | 0.99\n",
            "V143 | V95 | 0.99\n",
            "V143 | V101 | 0.99\n",
            "V143 | V126 | 0.98\n",
            "V143 | V132 | 0.99\n",
            "V150 | V144 | 0.96\n",
            "V150 | V145 | 0.98\n",
            "V153 | V148 | 0.95\n",
            "V155 | V148 | 0.98\n",
            "V155 | V153 | 0.96\n",
            "V156 | V149 | 0.98\n",
            "V159 | V150 | 0.97\n",
            "V159 | V151 | 0.96\n",
            "V160 | V145 | 0.96\n",
            "V164 | V95 | 0.99\n",
            "V164 | V101 | 0.99\n",
            "V164 | V126 | 0.98\n",
            "V164 | V132 | 0.99\n",
            "V164 | V143 | 1.0\n",
            "V167 | V95 | 0.99\n",
            "V167 | V101 | 0.99\n",
            "V167 | V126 | 0.99\n",
            "V167 | V132 | 0.99\n",
            "V167 | V143 | 0.98\n",
            "V167 | V164 | 0.99\n",
            "V168 | V96 | 0.98\n",
            "V168 | V97 | 0.98\n",
            "V168 | V102 | 0.98\n",
            "V168 | V103 | 0.98\n",
            "V168 | V127 | 0.97\n",
            "V168 | V128 | 0.98\n",
            "V168 | V133 | 0.97\n",
            "V168 | V134 | 0.98\n",
            "V177 | V95 | 0.99\n",
            "V177 | V101 | 0.99\n",
            "V177 | V126 | 0.99\n",
            "V177 | V132 | 0.99\n",
            "V177 | V143 | 0.98\n",
            "V177 | V164 | 0.99\n",
            "V177 | V167 | 1.0\n",
            "V178 | V96 | 0.99\n",
            "V178 | V97 | 0.97\n",
            "V178 | V102 | 0.99\n",
            "V178 | V103 | 0.98\n",
            "V178 | V127 | 0.99\n",
            "V178 | V128 | 0.97\n",
            "V178 | V133 | 0.99\n",
            "V178 | V134 | 0.98\n",
            "V178 | V167 | 0.95\n",
            "V178 | V168 | 0.99\n",
            "V179 | V96 | 0.99\n",
            "V179 | V97 | 0.99\n",
            "V179 | V102 | 0.99\n",
            "V179 | V103 | 0.99\n",
            "V179 | V127 | 0.98\n",
            "V179 | V128 | 0.98\n",
            "V179 | V133 | 0.98\n",
            "V179 | V134 | 0.99\n",
            "V179 | V168 | 1.0\n",
            "V182 | V180 | 0.99\n",
            "V192 | V187 | 0.96\n",
            "V196 | V191 | 0.97\n",
            "V199 | V190 | 0.96\n",
            "V202 | V95 | 0.98\n",
            "V202 | V101 | 0.98\n",
            "V202 | V126 | 0.99\n",
            "V202 | V132 | 0.98\n",
            "V202 | V143 | 0.97\n",
            "V202 | V164 | 0.98\n",
            "V202 | V167 | 0.99\n",
            "V202 | V177 | 0.99\n",
            "V204 | V168 | 0.98\n",
            "V204 | V178 | 0.96\n",
            "V204 | V179 | 0.96\n",
            "V206 | V129 | 0.96\n",
            "V211 | V95 | 0.99\n",
            "V211 | V101 | 0.99\n",
            "V211 | V126 | 0.99\n",
            "V211 | V132 | 0.99\n",
            "V211 | V143 | 0.98\n",
            "V211 | V164 | 0.99\n",
            "V211 | V167 | 1.0\n",
            "V211 | V177 | 1.0\n",
            "V211 | V178 | 0.95\n",
            "V211 | V202 | 0.99\n",
            "V212 | V96 | 0.96\n",
            "V212 | V102 | 0.97\n",
            "V212 | V103 | 0.95\n",
            "V212 | V127 | 0.96\n",
            "V212 | V128 | 0.95\n",
            "V212 | V133 | 0.97\n",
            "V212 | V134 | 0.96\n",
            "V212 | V168 | 0.98\n",
            "V212 | V178 | 0.99\n",
            "V212 | V179 | 0.97\n",
            "V212 | V203 | 0.96\n",
            "V212 | V204 | 0.98\n",
            "V213 | V96 | 0.98\n",
            "V213 | V97 | 0.98\n",
            "V213 | V102 | 0.98\n",
            "V213 | V103 | 0.98\n",
            "V213 | V127 | 0.98\n",
            "V213 | V128 | 0.98\n",
            "V213 | V133 | 0.98\n",
            "V213 | V134 | 0.98\n",
            "V213 | V168 | 1.0\n",
            "V213 | V178 | 0.99\n",
            "V213 | V179 | 1.0\n",
            "V213 | V204 | 0.98\n",
            "V217 | V167 | 0.96\n",
            "V217 | V168 | 0.95\n",
            "V217 | V177 | 0.96\n",
            "V217 | V179 | 0.95\n",
            "V219 | V167 | 0.95\n",
            "V219 | V168 | 0.96\n",
            "V219 | V178 | 0.95\n",
            "V219 | V179 | 0.95\n",
            "V219 | V217 | 0.98\n",
            "V231 | V167 | 0.96\n",
            "V231 | V177 | 0.96\n",
            "V231 | V179 | 0.95\n",
            "V231 | V217 | 1.0\n",
            "V231 | V219 | 0.97\n",
            "V232 | V168 | 0.95\n",
            "V232 | V177 | 0.95\n",
            "V232 | V178 | 0.95\n",
            "V232 | V179 | 0.96\n",
            "V232 | V217 | 0.98\n",
            "V232 | V218 | 0.95\n",
            "V232 | V219 | 0.99\n",
            "V233 | V167 | 0.95\n",
            "V233 | V168 | 0.96\n",
            "V233 | V177 | 0.96\n",
            "V233 | V178 | 0.96\n",
            "V233 | V179 | 0.96\n",
            "V233 | V217 | 0.99\n",
            "V233 | V219 | 0.99\n",
            "V233 | V231 | 0.99\n",
            "V236 | V234 | 0.98\n",
            "V244 | V242 | 0.97\n",
            "V253 | V248 | 0.96\n",
            "V254 | V248 | 0.95\n",
            "V263 | V202 | 0.97\n",
            "V265 | V204 | 0.95\n",
            "V266 | V129 | 0.96\n",
            "V266 | V205 | 0.98\n",
            "V266 | V206 | 0.96\n",
            "V269 | V129 | 0.96\n",
            "V269 | V205 | 0.98\n",
            "V269 | V206 | 0.96\n",
            "V269 | V266 | 1.0\n",
            "V272 | V270 | 0.96\n",
            "V273 | V211 | 0.96\n",
            "V273 | V217 | 0.95\n",
            "V273 | V231 | 0.95\n",
            "V275 | V213 | 0.96\n",
            "V276 | V214 | 0.99\n",
            "V277 | V215 | 0.95\n",
            "V278 | V215 | 0.97\n",
            "V278 | V216 | 0.98\n",
            "V279 | V95 | 1.0\n",
            "V279 | V101 | 1.0\n",
            "V279 | V126 | 0.98\n",
            "V279 | V132 | 0.99\n",
            "V279 | V143 | 0.99\n",
            "V279 | V164 | 0.99\n",
            "V279 | V167 | 0.99\n",
            "V279 | V177 | 0.99\n",
            "V279 | V202 | 0.98\n",
            "V279 | V211 | 0.99\n",
            "V280 | V96 | 0.98\n",
            "V280 | V97 | 0.99\n",
            "V280 | V102 | 0.98\n",
            "V280 | V103 | 0.99\n",
            "V280 | V127 | 0.97\n",
            "V280 | V128 | 0.98\n",
            "V280 | V133 | 0.97\n",
            "V280 | V134 | 0.98\n",
            "V280 | V168 | 0.98\n",
            "V280 | V178 | 0.97\n",
            "V280 | V179 | 0.99\n",
            "V280 | V213 | 0.98\n",
            "V293 | V95 | 1.0\n",
            "V293 | V101 | 1.0\n",
            "V293 | V126 | 0.98\n",
            "V293 | V132 | 0.99\n",
            "V293 | V143 | 0.99\n",
            "V293 | V164 | 0.99\n",
            "V293 | V167 | 0.99\n",
            "V293 | V177 | 0.99\n",
            "V293 | V202 | 0.98\n",
            "V293 | V211 | 0.99\n",
            "V293 | V279 | 1.0\n",
            "V294 | V168 | 0.96\n",
            "V294 | V178 | 0.98\n",
            "V294 | V179 | 0.97\n",
            "V294 | V212 | 0.95\n",
            "V294 | V213 | 0.97\n",
            "V295 | V96 | 0.98\n",
            "V295 | V97 | 0.99\n",
            "V295 | V102 | 0.98\n",
            "V295 | V103 | 0.99\n",
            "V295 | V127 | 0.97\n",
            "V295 | V128 | 0.97\n",
            "V295 | V133 | 0.97\n",
            "V295 | V134 | 0.98\n",
            "V295 | V168 | 0.98\n",
            "V295 | V178 | 0.98\n",
            "V295 | V179 | 0.99\n",
            "V295 | V212 | 0.95\n",
            "V295 | V213 | 0.98\n",
            "V295 | V280 | 1.0\n",
            "V296 | V105 | 0.96\n",
            "V298 | V105 | 0.98\n",
            "V298 | V296 | 0.99\n",
            "V299 | V105 | 0.95\n",
            "V299 | V106 | 0.98\n",
            "V304 | V302 | 0.96\n",
            "V306 | V95 | 0.98\n",
            "V306 | V101 | 0.98\n",
            "V306 | V126 | 0.99\n",
            "V306 | V132 | 0.98\n",
            "V306 | V143 | 0.98\n",
            "V306 | V164 | 0.98\n",
            "V306 | V167 | 0.98\n",
            "V306 | V177 | 0.98\n",
            "V306 | V202 | 0.99\n",
            "V306 | V211 | 0.98\n",
            "V306 | V279 | 0.98\n",
            "V306 | V293 | 0.98\n",
            "V307 | V127 | 0.96\n",
            "V307 | V133 | 0.95\n",
            "V307 | V168 | 0.97\n",
            "V307 | V178 | 0.98\n",
            "V307 | V179 | 0.98\n",
            "V307 | V212 | 0.96\n",
            "V307 | V213 | 0.97\n",
            "V307 | V280 | 0.97\n",
            "V307 | V294 | 0.97\n",
            "V307 | V295 | 0.97\n",
            "V308 | V96 | 0.97\n",
            "V308 | V97 | 0.98\n",
            "V308 | V102 | 0.97\n",
            "V308 | V103 | 0.98\n",
            "V308 | V127 | 0.98\n",
            "V308 | V128 | 0.99\n",
            "V308 | V133 | 0.97\n",
            "V308 | V134 | 0.98\n",
            "V308 | V168 | 0.97\n",
            "V308 | V178 | 0.97\n",
            "V308 | V179 | 0.98\n",
            "V308 | V213 | 0.98\n",
            "V308 | V280 | 0.98\n",
            "V308 | V295 | 0.98\n",
            "V311 | V206 | 0.97\n",
            "V316 | V95 | 0.99\n",
            "V316 | V101 | 0.99\n",
            "V316 | V126 | 0.99\n",
            "V316 | V132 | 1.0\n",
            "V316 | V143 | 0.99\n",
            "V316 | V164 | 0.99\n",
            "V316 | V167 | 0.99\n",
            "V316 | V177 | 0.99\n",
            "V316 | V202 | 0.98\n",
            "V316 | V211 | 0.99\n",
            "V316 | V279 | 0.99\n",
            "V316 | V293 | 0.99\n",
            "V316 | V306 | 0.99\n",
            "V317 | V133 | 0.95\n",
            "V317 | V168 | 0.97\n",
            "V317 | V178 | 0.98\n",
            "V317 | V179 | 0.98\n",
            "V317 | V212 | 0.96\n",
            "V317 | V213 | 0.98\n",
            "V317 | V280 | 0.97\n",
            "V317 | V294 | 0.98\n",
            "V317 | V295 | 0.97\n",
            "V317 | V307 | 0.99\n",
            "V317 | V308 | 0.96\n",
            "V318 | V96 | 0.98\n",
            "V318 | V97 | 0.99\n",
            "V318 | V102 | 0.98\n",
            "V318 | V103 | 0.99\n",
            "V318 | V127 | 0.98\n",
            "V318 | V128 | 0.98\n",
            "V318 | V133 | 0.98\n",
            "V318 | V134 | 0.99\n",
            "V318 | V168 | 0.98\n",
            "V318 | V178 | 0.98\n",
            "V318 | V179 | 0.99\n",
            "V318 | V212 | 0.96\n",
            "V318 | V213 | 0.98\n",
            "V318 | V280 | 0.99\n",
            "V318 | V295 | 0.99\n",
            "V318 | V307 | 0.97\n",
            "V318 | V308 | 0.99\n",
            "V322 | V95 | 1.0\n",
            "V322 | V101 | 1.0\n",
            "V322 | V126 | 0.99\n",
            "V322 | V132 | 1.0\n",
            "V322 | V133 | 0.95\n",
            "V322 | V143 | 0.99\n",
            "V322 | V164 | 0.99\n",
            "V322 | V167 | 0.99\n",
            "V322 | V177 | 0.99\n",
            "V322 | V202 | 0.98\n",
            "V322 | V211 | 0.99\n",
            "V322 | V279 | 1.0\n",
            "V322 | V293 | 1.0\n",
            "V322 | V306 | 0.99\n",
            "V322 | V316 | 1.0\n",
            "V322 | V317 | 0.95\n",
            "V323 | V96 | 1.0\n",
            "V323 | V97 | 0.99\n",
            "V323 | V102 | 1.0\n",
            "V323 | V103 | 0.99\n",
            "V323 | V105 | 0.95\n",
            "V323 | V127 | 0.99\n",
            "V323 | V128 | 0.99\n",
            "V323 | V133 | 1.0\n",
            "V323 | V134 | 0.99\n",
            "V323 | V168 | 0.98\n",
            "V323 | V178 | 0.99\n",
            "V323 | V179 | 0.99\n",
            "V323 | V212 | 0.96\n",
            "V323 | V213 | 0.98\n",
            "V323 | V280 | 0.99\n",
            "V323 | V294 | 1.0\n",
            "V323 | V295 | 0.99\n",
            "V323 | V307 | 0.99\n",
            "V323 | V308 | 0.99\n",
            "V323 | V317 | 1.0\n",
            "V323 | V318 | 0.99\n",
            "V324 | V96 | 0.99\n",
            "V324 | V97 | 1.0\n",
            "V324 | V102 | 0.99\n",
            "V324 | V103 | 1.0\n",
            "V324 | V105 | 0.96\n",
            "V324 | V127 | 0.99\n",
            "V324 | V128 | 0.99\n",
            "V324 | V133 | 0.99\n",
            "V324 | V134 | 1.0\n",
            "V324 | V168 | 0.98\n",
            "V324 | V178 | 0.98\n",
            "V324 | V179 | 0.99\n",
            "V324 | V213 | 0.98\n",
            "V324 | V280 | 1.0\n",
            "V324 | V294 | 0.99\n",
            "V324 | V295 | 1.0\n",
            "V324 | V298 | 0.96\n",
            "V324 | V307 | 0.98\n",
            "V324 | V308 | 0.99\n",
            "V324 | V317 | 0.99\n",
            "V324 | V318 | 1.0\n",
            "V326 | V99 | 0.99\n",
            "V326 | V285 | 0.96\n",
            "V327 | V100 | 0.99\n",
            "V327 | V287 | 0.97\n",
            "V328 | V104 | 0.99\n",
            "V328 | V297 | 0.97\n",
            "V329 | V96 | 0.95\n",
            "V329 | V97 | 0.96\n",
            "V329 | V103 | 0.95\n",
            "V329 | V105 | 1.0\n",
            "V329 | V106 | 0.97\n",
            "V329 | V280 | 0.96\n",
            "V329 | V295 | 0.95\n",
            "V329 | V296 | 0.99\n",
            "V329 | V298 | 1.0\n",
            "V329 | V299 | 0.97\n",
            "V329 | V323 | 0.95\n",
            "V329 | V324 | 0.96\n",
            "V330 | V105 | 0.97\n",
            "V330 | V106 | 1.0\n",
            "V330 | V296 | 0.96\n",
            "V330 | V298 | 0.96\n",
            "V330 | V299 | 0.99\n",
            "V331 | V95 | 0.99\n",
            "V331 | V101 | 0.99\n",
            "V331 | V126 | 1.0\n",
            "V331 | V132 | 0.99\n",
            "V331 | V143 | 0.98\n",
            "V331 | V164 | 0.98\n",
            "V331 | V167 | 0.99\n",
            "V331 | V177 | 0.99\n",
            "V331 | V202 | 0.99\n",
            "V331 | V211 | 0.99\n",
            "V331 | V279 | 0.99\n",
            "V331 | V293 | 0.99\n",
            "V331 | V306 | 0.99\n",
            "V331 | V316 | 0.99\n",
            "V331 | V322 | 0.99\n",
            "V332 | V96 | 0.99\n",
            "V332 | V97 | 0.99\n",
            "V332 | V102 | 0.99\n",
            "V332 | V103 | 0.99\n",
            "V332 | V127 | 1.0\n",
            "V332 | V128 | 0.99\n",
            "V332 | V133 | 1.0\n",
            "V332 | V134 | 0.99\n",
            "V332 | V168 | 0.97\n",
            "V332 | V178 | 0.99\n",
            "V332 | V179 | 0.98\n",
            "V332 | V212 | 0.96\n",
            "V332 | V213 | 0.98\n",
            "V332 | V280 | 0.99\n",
            "V332 | V294 | 0.99\n",
            "V332 | V295 | 0.99\n",
            "V332 | V307 | 1.0\n",
            "V332 | V308 | 0.99\n",
            "V332 | V317 | 1.0\n",
            "V332 | V318 | 0.99\n",
            "V332 | V323 | 0.99\n",
            "V332 | V324 | 0.99\n",
            "V333 | V96 | 0.99\n",
            "V333 | V97 | 0.99\n",
            "V333 | V102 | 0.98\n",
            "V333 | V103 | 0.99\n",
            "V333 | V105 | 0.95\n",
            "V333 | V127 | 0.99\n",
            "V333 | V128 | 1.0\n",
            "V333 | V133 | 0.98\n",
            "V333 | V134 | 0.99\n",
            "V333 | V168 | 0.98\n",
            "V333 | V178 | 0.97\n",
            "V333 | V179 | 0.98\n",
            "V333 | V212 | 0.95\n",
            "V333 | V213 | 0.98\n",
            "V333 | V280 | 0.99\n",
            "V333 | V294 | 0.98\n",
            "V333 | V295 | 0.99\n",
            "V333 | V307 | 0.99\n",
            "V333 | V308 | 1.0\n",
            "V333 | V317 | 0.98\n",
            "V333 | V318 | 0.99\n",
            "V333 | V323 | 0.99\n",
            "V333 | V324 | 0.99\n",
            "V333 | V329 | 0.95\n",
            "V334 | V309 | 0.95\n",
            "Удалено признаков:\n",
            "99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделение столбцов по типам и по заполненностью данными:"
      ],
      "metadata": {
        "id": "TpiyoIMvypQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_train.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTWM4fsyzFI2",
        "outputId": "cd615c2e-1a3c-4360-e48f-cb5f81f56175"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransactionAmt    float64\n",
            "ProductCD          object\n",
            "card1               int64\n",
            "card2             float64\n",
            "card3             float64\n",
            "                   ...   \n",
            "id_34              object\n",
            "id_35              object\n",
            "id_36              object\n",
            "id_37              object\n",
            "id_38              object\n",
            "Length: 429, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.numerictypes import obj2sctype\n",
        "def create_column_lists(data, max_nan=0.8):\n",
        "  column_dict={}\n",
        "  column_dict['categorical_column'] = []\n",
        "  column_dict['numeric_column'] = []\n",
        "  column_dict['float_column'] = []\n",
        "  column_dict['bad_categorical_column'] = []\n",
        "  column_dict['bad_numeric_column'] = []\n",
        "  column_dict['bad_float_column'] = []\n",
        "  for column in data.columns:\n",
        "    row_count = data[column].shape[0]\n",
        "    if data[column].isna().sum()/row_count > max_nan:\n",
        "      if data[column].dtypes == object:\n",
        "        column_dict['bad_categorical_column'].append(column)\n",
        "      else:\n",
        "        if data[column].dtypes == float:\n",
        "          column_dict['bad_float_column'].append(column)\n",
        "        else:\n",
        "          column_dict['bad_numeric_column'].append(column)\n",
        "    else:\n",
        "      if data[column].dtypes == object:\n",
        "        column_dict['categorical_column'].append(column)\n",
        "      else:\n",
        "        if data[column].dtypes == float:\n",
        "          column_dict['float_column'].append(column)\n",
        "        else:\n",
        "          column_dict['numeric_column'].append(column)\n",
        "  return column_dict\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0V4AGJh0tfi6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_dict = create_column_lists(df_train, nan_percent)\n",
        "for key in column_dict:\n",
        "  print(key+':')\n",
        "  print(column_dict[key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU6ht5h19l3H",
        "outputId": "6f516d16-271d-4aa9-e94e-15a97a8b7e35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categorical_column:\n",
            "['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15', 'id_16', 'id_28', 'id_29', 'id_30', 'id_31', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38']\n",
            "numeric_column:\n",
            "['card1']\n",
            "float_column:\n",
            "['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', 'addr2', 'dist1', 'dist2', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_09', 'id_10', 'id_11', 'id_13', 'id_14', 'id_17', 'id_18', 'id_19', 'id_20', 'id_32']\n",
            "bad_categorical_column:\n",
            "['id_23', 'id_27']\n",
            "bad_numeric_column:\n",
            "[]\n",
            "bad_float_column:\n",
            "['id_07', 'id_08', 'id_21', 'id_22', 'id_24', 'id_25', 'id_26']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in column_dict:\n",
        "  print(key+':')\n",
        "  print(column_dict[key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmytC4xRmfNv",
        "outputId": "c7f530f9-6002-4316-f1f2-a9a1df8b3083"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categorical_column:\n",
            "['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15', 'id_16', 'id_28', 'id_29', 'id_30', 'id_31', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'id_23', 'id_27']\n",
            "numeric_column:\n",
            "['card1']\n",
            "float_column:\n",
            "['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', 'addr2', 'dist1', 'dist2', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_09', 'id_10', 'id_11', 'id_13', 'id_14', 'id_17', 'id_18', 'id_19', 'id_20', 'id_32', 'id_07', 'id_08', 'id_21', 'id_22', 'id_24', 'id_25', 'id_26']\n",
            "bad_categorical_column:\n",
            "['id_23', 'id_27']\n",
            "bad_numeric_column:\n",
            "[]\n",
            "bad_float_column:\n",
            "['id_07', 'id_08', 'id_21', 'id_22', 'id_24', 'id_25', 'id_26']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разбираемся с почти пустыми столбцами"
      ],
      "metadata": {
        "id": "a7vxUPybFrdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_data(data,column_dict,is_drop_nan = False, is_test = False):\n",
        "  if is_drop_nan == True:\n",
        "    data.drop(columns=column_dict['bad_float_column']+\n",
        "            column_dict['bad_numeric_column']+\n",
        "            column_dict['bad_categorical_column'],axis = 1,inplace = True)  \n",
        "  else:\n",
        "    for column in column_dict['bad_categorical_column']:\n",
        "      data[column].fillna(bad_fill_category_value, inplace = True)\n",
        "    for column in column_dict['bad_float_column']:\n",
        "      data[column].fillna(bad_fill_float_value, inplace = True)\n",
        "    for column in column_dict['bad_numeric_column']:\n",
        "      data[column].fillna(bad_fill_numeric_value, inplace = True)\n",
        "    if is_test == False:\n",
        "      column_dict['categorical_column'] = column_dict['categorical_column']+\\\n",
        "        column_dict['bad_categorical_column']\n",
        "      column_dict['float_column'] = column_dict['float_column']+\\\n",
        "        column_dict['bad_float_column']\n",
        "      column_dict['numeric_column'] = column_dict['numeric_column']+\\\n",
        "        column_dict['bad_numeric_column']\n",
        "\n",
        "  \"\"\"column_dict['bad_categorical_column']=[]\n",
        "  column_dict['bad_float_column']=[]\n",
        "  column_dict['bad_numeric_column']=[]\"\"\"\n",
        "\n",
        "  for column in column_dict['categorical_column']:\n",
        "    data[column].fillna(bad_fill_category_value, inplace = True)\n",
        "  for column in column_dict['float_column']:\n",
        "    data[column].fillna(data[column].mean(), inplace = True)\n",
        "  for column in column_dict['numeric_column']:\n",
        "    data[column].fillna(data[column].mean(), inplace = True)\n",
        "\n",
        "  return data, column_dict\n"
      ],
      "metadata": {
        "id": "VhhsNUfJ_13t"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train,column_dict = fill_data(df_train,column_dict,is_drop_nan_columns, False)"
      ],
      "metadata": {
        "id": "tHfAfcr2JBhG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Готовим данные"
      ],
      "metadata": {
        "id": "4GpHS3OMNWnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(df_train, df_y, test_size = 0.3, random_state = 42)\n"
      ],
      "metadata": {
        "id": "ve0orwADMLLF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df_train,df_y\n",
        "gc.collect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShBTIrBwPpiq",
        "outputId": "c770ee85-6afb-4905-ed8a-d4b63a8c9947"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function gc.collect>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "if is_need_pca == True:\n",
        "  pca = PCA(15)\n",
        "  pca.fit(X_train[column_dict['float_column']+column_dict['numeric_column']])\n",
        "  plt.plot(pca.explained_variance_ratio_.cumsum())\n",
        "  plt.axvline(x=4)\n",
        "  plt.grid()\n",
        "  X_train_pca_part = pca.transform(X_train[column_dict['float_column']+column_dict['numeric_column']])\n",
        "  X_val_pca_part = pca.transform(X_val[column_dict['float_column']+column_dict['numeric_column']])"
      ],
      "metadata": {
        "id": "_fA5vrF3Nxju"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xO2PO3VnN4wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoost"
      ],
      "metadata": {
        "id": "xweJw0CrQ3kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q catboost shap"
      ],
      "metadata": {
        "id": "-R4OmPLYRLSq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "model = CatBoostClassifier()\n",
        "if is_need_pca == True: \n",
        "  model.fit(X_train_pca_part, y_train) \n",
        "  y_pred = model.predict(X_val_pca_part) \n",
        "else:\n",
        "  model.fit(X_train[column_dict['float_column']+column_dict['numeric_column']], y_train) \n",
        "  y_pred = model.predict(X_val[column_dict['float_column']+column_dict['numeric_column']]) \n",
        "print(f\"{roc_auc_score(y_pred, y_val)}\")\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EM_PnreRMkz",
        "outputId": "892dcceb-97e1-4f9e-9f80-6eef28ea810e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.134932\n",
            "0:\tlearn: 0.4943229\ttotal: 1.05s\tremaining: 17m 31s\n",
            "1:\tlearn: 0.3546477\ttotal: 2.13s\tremaining: 17m 44s\n",
            "2:\tlearn: 0.2747348\ttotal: 2.91s\tremaining: 16m 7s\n",
            "3:\tlearn: 0.2221633\ttotal: 3.96s\tremaining: 16m 27s\n",
            "4:\tlearn: 0.1891102\ttotal: 4.86s\tremaining: 16m 7s\n",
            "5:\tlearn: 0.1671098\ttotal: 5.72s\tremaining: 15m 47s\n",
            "6:\tlearn: 0.1502516\ttotal: 6.68s\tremaining: 15m 47s\n",
            "7:\tlearn: 0.1390413\ttotal: 7.48s\tremaining: 15m 27s\n",
            "8:\tlearn: 0.1301802\ttotal: 8.14s\tremaining: 14m 56s\n",
            "9:\tlearn: 0.1243470\ttotal: 9.16s\tremaining: 15m 6s\n",
            "10:\tlearn: 0.1200537\ttotal: 10.3s\tremaining: 15m 27s\n",
            "11:\tlearn: 0.1162353\ttotal: 11.5s\tremaining: 15m 46s\n",
            "12:\tlearn: 0.1141336\ttotal: 12.3s\tremaining: 15m 35s\n",
            "13:\tlearn: 0.1120221\ttotal: 13.5s\tremaining: 15m 51s\n",
            "14:\tlearn: 0.1101630\ttotal: 14.5s\tremaining: 15m 50s\n",
            "15:\tlearn: 0.1088035\ttotal: 15.4s\tremaining: 15m 49s\n",
            "16:\tlearn: 0.1078082\ttotal: 16.4s\tremaining: 15m 48s\n",
            "17:\tlearn: 0.1065366\ttotal: 17.7s\tremaining: 16m 4s\n",
            "18:\tlearn: 0.1058272\ttotal: 18.7s\tremaining: 16m 3s\n",
            "19:\tlearn: 0.1052925\ttotal: 19.8s\tremaining: 16m 9s\n",
            "20:\tlearn: 0.1044828\ttotal: 20.8s\tremaining: 16m 11s\n",
            "21:\tlearn: 0.1037131\ttotal: 21.8s\tremaining: 16m 11s\n",
            "22:\tlearn: 0.1032281\ttotal: 22.7s\tremaining: 16m 5s\n",
            "23:\tlearn: 0.1026277\ttotal: 23.9s\tremaining: 16m 13s\n",
            "24:\tlearn: 0.1021537\ttotal: 24.7s\tremaining: 16m 2s\n",
            "25:\tlearn: 0.1018110\ttotal: 25.7s\tremaining: 16m 1s\n",
            "26:\tlearn: 0.1013604\ttotal: 26.6s\tremaining: 15m 58s\n",
            "27:\tlearn: 0.1011017\ttotal: 27.5s\tremaining: 15m 54s\n",
            "28:\tlearn: 0.1007267\ttotal: 28.5s\tremaining: 15m 53s\n",
            "29:\tlearn: 0.1002214\ttotal: 29.5s\tremaining: 15m 53s\n",
            "30:\tlearn: 0.0997901\ttotal: 30.6s\tremaining: 15m 57s\n",
            "31:\tlearn: 0.0994603\ttotal: 31.7s\tremaining: 15m 58s\n",
            "32:\tlearn: 0.0991914\ttotal: 32.5s\tremaining: 15m 51s\n",
            "33:\tlearn: 0.0989212\ttotal: 33.4s\tremaining: 15m 48s\n",
            "34:\tlearn: 0.0986881\ttotal: 34.5s\tremaining: 15m 51s\n",
            "35:\tlearn: 0.0984265\ttotal: 35s\tremaining: 15m 36s\n",
            "36:\tlearn: 0.0982310\ttotal: 35.4s\tremaining: 15m 20s\n",
            "37:\tlearn: 0.0980353\ttotal: 35.9s\tremaining: 15m 9s\n",
            "38:\tlearn: 0.0978599\ttotal: 36.4s\tremaining: 14m 56s\n",
            "39:\tlearn: 0.0975989\ttotal: 36.9s\tremaining: 14m 45s\n",
            "40:\tlearn: 0.0973442\ttotal: 37.3s\tremaining: 14m 33s\n",
            "41:\tlearn: 0.0971211\ttotal: 37.8s\tremaining: 14m 23s\n",
            "42:\tlearn: 0.0969089\ttotal: 38.3s\tremaining: 14m 12s\n",
            "43:\tlearn: 0.0967360\ttotal: 38.8s\tremaining: 14m 3s\n",
            "44:\tlearn: 0.0965583\ttotal: 39.3s\tremaining: 13m 53s\n",
            "45:\tlearn: 0.0963974\ttotal: 39.8s\tremaining: 13m 45s\n",
            "46:\tlearn: 0.0961584\ttotal: 40.3s\tremaining: 13m 37s\n",
            "47:\tlearn: 0.0959917\ttotal: 40.7s\tremaining: 13m 27s\n",
            "48:\tlearn: 0.0958354\ttotal: 41.2s\tremaining: 13m 20s\n",
            "49:\tlearn: 0.0956681\ttotal: 41.7s\tremaining: 13m 12s\n",
            "50:\tlearn: 0.0955221\ttotal: 42.2s\tremaining: 13m 4s\n",
            "51:\tlearn: 0.0953535\ttotal: 42.7s\tremaining: 12m 57s\n",
            "52:\tlearn: 0.0951968\ttotal: 43.2s\tremaining: 12m 51s\n",
            "53:\tlearn: 0.0950262\ttotal: 43.7s\tremaining: 12m 45s\n",
            "54:\tlearn: 0.0948945\ttotal: 44.1s\tremaining: 12m 37s\n",
            "55:\tlearn: 0.0947756\ttotal: 44.5s\tremaining: 12m 30s\n",
            "56:\tlearn: 0.0946411\ttotal: 44.9s\tremaining: 12m 23s\n",
            "57:\tlearn: 0.0943552\ttotal: 45.4s\tremaining: 12m 17s\n",
            "58:\tlearn: 0.0940971\ttotal: 45.9s\tremaining: 12m 12s\n",
            "59:\tlearn: 0.0939948\ttotal: 46.4s\tremaining: 12m 6s\n",
            "60:\tlearn: 0.0938781\ttotal: 46.8s\tremaining: 11m 59s\n",
            "61:\tlearn: 0.0936989\ttotal: 47.2s\tremaining: 11m 53s\n",
            "62:\tlearn: 0.0934953\ttotal: 47.6s\tremaining: 11m 48s\n",
            "63:\tlearn: 0.0933503\ttotal: 48.2s\tremaining: 11m 44s\n",
            "64:\tlearn: 0.0931623\ttotal: 48.6s\tremaining: 11m 39s\n",
            "65:\tlearn: 0.0930711\ttotal: 49s\tremaining: 11m 33s\n",
            "66:\tlearn: 0.0929291\ttotal: 49.5s\tremaining: 11m 29s\n",
            "67:\tlearn: 0.0927736\ttotal: 50s\tremaining: 11m 25s\n",
            "68:\tlearn: 0.0926196\ttotal: 50.5s\tremaining: 11m 21s\n",
            "69:\tlearn: 0.0925309\ttotal: 50.9s\tremaining: 11m 16s\n",
            "70:\tlearn: 0.0923982\ttotal: 51.4s\tremaining: 11m 12s\n",
            "71:\tlearn: 0.0922909\ttotal: 51.8s\tremaining: 11m 7s\n",
            "72:\tlearn: 0.0921300\ttotal: 52.2s\tremaining: 11m 3s\n",
            "73:\tlearn: 0.0919518\ttotal: 52.7s\tremaining: 10m 59s\n",
            "74:\tlearn: 0.0918930\ttotal: 53.2s\tremaining: 10m 55s\n",
            "75:\tlearn: 0.0917899\ttotal: 53.6s\tremaining: 10m 51s\n",
            "76:\tlearn: 0.0916347\ttotal: 54s\tremaining: 10m 47s\n",
            "77:\tlearn: 0.0915679\ttotal: 54.4s\tremaining: 10m 43s\n",
            "78:\tlearn: 0.0914332\ttotal: 54.9s\tremaining: 10m 40s\n",
            "79:\tlearn: 0.0913270\ttotal: 55.5s\tremaining: 10m 38s\n",
            "80:\tlearn: 0.0911924\ttotal: 56s\tremaining: 10m 35s\n",
            "81:\tlearn: 0.0911164\ttotal: 56.4s\tremaining: 10m 31s\n",
            "82:\tlearn: 0.0909787\ttotal: 57s\tremaining: 10m 29s\n",
            "83:\tlearn: 0.0908551\ttotal: 57.5s\tremaining: 10m 27s\n",
            "84:\tlearn: 0.0907802\ttotal: 58s\tremaining: 10m 23s\n",
            "85:\tlearn: 0.0907446\ttotal: 58.3s\tremaining: 10m 19s\n",
            "86:\tlearn: 0.0906866\ttotal: 58.7s\tremaining: 10m 16s\n",
            "87:\tlearn: 0.0906231\ttotal: 59.1s\tremaining: 10m 12s\n",
            "88:\tlearn: 0.0904831\ttotal: 59.6s\tremaining: 10m 9s\n",
            "89:\tlearn: 0.0903291\ttotal: 1m\tremaining: 10m 7s\n",
            "90:\tlearn: 0.0902643\ttotal: 1m\tremaining: 10m 3s\n",
            "91:\tlearn: 0.0901792\ttotal: 1m\tremaining: 10m\n",
            "92:\tlearn: 0.0899971\ttotal: 1m 1s\tremaining: 9m 58s\n",
            "93:\tlearn: 0.0899513\ttotal: 1m 1s\tremaining: 9m 55s\n",
            "94:\tlearn: 0.0898685\ttotal: 1m 2s\tremaining: 9m 53s\n",
            "95:\tlearn: 0.0897198\ttotal: 1m 2s\tremaining: 9m 51s\n",
            "96:\tlearn: 0.0895944\ttotal: 1m 3s\tremaining: 9m 48s\n",
            "97:\tlearn: 0.0893975\ttotal: 1m 3s\tremaining: 9m 46s\n",
            "98:\tlearn: 0.0892942\ttotal: 1m 4s\tremaining: 9m 44s\n",
            "99:\tlearn: 0.0892363\ttotal: 1m 4s\tremaining: 9m 41s\n",
            "100:\tlearn: 0.0891583\ttotal: 1m 4s\tremaining: 9m 38s\n",
            "101:\tlearn: 0.0891123\ttotal: 1m 5s\tremaining: 9m 35s\n",
            "102:\tlearn: 0.0889765\ttotal: 1m 5s\tremaining: 9m 34s\n",
            "103:\tlearn: 0.0889128\ttotal: 1m 6s\tremaining: 9m 31s\n",
            "104:\tlearn: 0.0888649\ttotal: 1m 6s\tremaining: 9m 28s\n",
            "105:\tlearn: 0.0888053\ttotal: 1m 7s\tremaining: 9m 25s\n",
            "106:\tlearn: 0.0886942\ttotal: 1m 7s\tremaining: 9m 23s\n",
            "107:\tlearn: 0.0885851\ttotal: 1m 8s\tremaining: 9m 21s\n",
            "108:\tlearn: 0.0885012\ttotal: 1m 8s\tremaining: 9m 19s\n",
            "109:\tlearn: 0.0883939\ttotal: 1m 8s\tremaining: 9m 16s\n",
            "110:\tlearn: 0.0883410\ttotal: 1m 9s\tremaining: 9m 14s\n",
            "111:\tlearn: 0.0881906\ttotal: 1m 9s\tremaining: 9m 13s\n",
            "112:\tlearn: 0.0880854\ttotal: 1m 10s\tremaining: 9m 11s\n",
            "113:\tlearn: 0.0880155\ttotal: 1m 10s\tremaining: 9m 9s\n",
            "114:\tlearn: 0.0879615\ttotal: 1m 11s\tremaining: 9m 7s\n",
            "115:\tlearn: 0.0878317\ttotal: 1m 11s\tremaining: 9m 5s\n",
            "116:\tlearn: 0.0877178\ttotal: 1m 12s\tremaining: 9m 4s\n",
            "117:\tlearn: 0.0876166\ttotal: 1m 12s\tremaining: 9m 2s\n",
            "118:\tlearn: 0.0875334\ttotal: 1m 12s\tremaining: 9m\n",
            "119:\tlearn: 0.0874400\ttotal: 1m 13s\tremaining: 8m 58s\n",
            "120:\tlearn: 0.0873502\ttotal: 1m 13s\tremaining: 8m 57s\n",
            "121:\tlearn: 0.0872262\ttotal: 1m 14s\tremaining: 8m 56s\n",
            "122:\tlearn: 0.0871630\ttotal: 1m 14s\tremaining: 8m 53s\n",
            "123:\tlearn: 0.0870269\ttotal: 1m 15s\tremaining: 8m 52s\n",
            "124:\tlearn: 0.0869948\ttotal: 1m 15s\tremaining: 8m 50s\n",
            "125:\tlearn: 0.0869410\ttotal: 1m 16s\tremaining: 8m 48s\n",
            "126:\tlearn: 0.0868185\ttotal: 1m 16s\tremaining: 8m 47s\n",
            "127:\tlearn: 0.0867862\ttotal: 1m 17s\tremaining: 8m 44s\n",
            "128:\tlearn: 0.0867185\ttotal: 1m 17s\tremaining: 8m 42s\n",
            "129:\tlearn: 0.0866548\ttotal: 1m 18s\tremaining: 8m 42s\n",
            "130:\tlearn: 0.0865780\ttotal: 1m 18s\tremaining: 8m 43s\n",
            "131:\tlearn: 0.0864761\ttotal: 1m 19s\tremaining: 8m 45s\n",
            "132:\tlearn: 0.0863689\ttotal: 1m 21s\tremaining: 8m 49s\n",
            "133:\tlearn: 0.0862828\ttotal: 1m 21s\tremaining: 8m 48s\n",
            "134:\tlearn: 0.0861896\ttotal: 1m 22s\tremaining: 8m 47s\n",
            "135:\tlearn: 0.0861297\ttotal: 1m 22s\tremaining: 8m 45s\n",
            "136:\tlearn: 0.0860273\ttotal: 1m 23s\tremaining: 8m 44s\n",
            "137:\tlearn: 0.0859507\ttotal: 1m 23s\tremaining: 8m 42s\n",
            "138:\tlearn: 0.0858860\ttotal: 1m 24s\tremaining: 8m 40s\n",
            "139:\tlearn: 0.0858173\ttotal: 1m 24s\tremaining: 8m 39s\n",
            "140:\tlearn: 0.0857362\ttotal: 1m 25s\tremaining: 8m 38s\n",
            "141:\tlearn: 0.0856478\ttotal: 1m 25s\tremaining: 8m 36s\n",
            "142:\tlearn: 0.0855987\ttotal: 1m 25s\tremaining: 8m 34s\n",
            "143:\tlearn: 0.0855421\ttotal: 1m 26s\tremaining: 8m 32s\n",
            "144:\tlearn: 0.0854416\ttotal: 1m 26s\tremaining: 8m 31s\n",
            "145:\tlearn: 0.0853810\ttotal: 1m 27s\tremaining: 8m 29s\n",
            "146:\tlearn: 0.0852878\ttotal: 1m 27s\tremaining: 8m 28s\n",
            "147:\tlearn: 0.0852595\ttotal: 1m 28s\tremaining: 8m 26s\n",
            "148:\tlearn: 0.0852132\ttotal: 1m 28s\tremaining: 8m 25s\n",
            "149:\tlearn: 0.0851477\ttotal: 1m 28s\tremaining: 8m 24s\n",
            "150:\tlearn: 0.0850656\ttotal: 1m 29s\tremaining: 8m 23s\n",
            "151:\tlearn: 0.0849758\ttotal: 1m 30s\tremaining: 8m 22s\n",
            "152:\tlearn: 0.0849258\ttotal: 1m 30s\tremaining: 8m 20s\n",
            "153:\tlearn: 0.0848483\ttotal: 1m 30s\tremaining: 8m 19s\n",
            "154:\tlearn: 0.0847625\ttotal: 1m 31s\tremaining: 8m 18s\n",
            "155:\tlearn: 0.0847200\ttotal: 1m 31s\tremaining: 8m 16s\n",
            "156:\tlearn: 0.0846563\ttotal: 1m 32s\tremaining: 8m 15s\n",
            "157:\tlearn: 0.0845786\ttotal: 1m 32s\tremaining: 8m 14s\n",
            "158:\tlearn: 0.0845036\ttotal: 1m 33s\tremaining: 8m 13s\n",
            "159:\tlearn: 0.0844348\ttotal: 1m 33s\tremaining: 8m 12s\n",
            "160:\tlearn: 0.0844022\ttotal: 1m 34s\tremaining: 8m 10s\n",
            "161:\tlearn: 0.0843596\ttotal: 1m 34s\tremaining: 8m 9s\n",
            "162:\tlearn: 0.0843106\ttotal: 1m 35s\tremaining: 8m 7s\n",
            "163:\tlearn: 0.0842339\ttotal: 1m 35s\tremaining: 8m 6s\n",
            "164:\tlearn: 0.0841656\ttotal: 1m 35s\tremaining: 8m 5s\n",
            "165:\tlearn: 0.0840851\ttotal: 1m 36s\tremaining: 8m 4s\n",
            "166:\tlearn: 0.0840653\ttotal: 1m 36s\tremaining: 8m 2s\n",
            "167:\tlearn: 0.0840303\ttotal: 1m 37s\tremaining: 8m 1s\n",
            "168:\tlearn: 0.0839161\ttotal: 1m 37s\tremaining: 8m 1s\n",
            "169:\tlearn: 0.0838407\ttotal: 1m 38s\tremaining: 8m\n",
            "170:\tlearn: 0.0837945\ttotal: 1m 38s\tremaining: 7m 59s\n",
            "171:\tlearn: 0.0837286\ttotal: 1m 39s\tremaining: 7m 58s\n",
            "172:\tlearn: 0.0836478\ttotal: 1m 39s\tremaining: 7m 56s\n",
            "173:\tlearn: 0.0835837\ttotal: 1m 40s\tremaining: 7m 55s\n",
            "174:\tlearn: 0.0835339\ttotal: 1m 40s\tremaining: 7m 54s\n",
            "175:\tlearn: 0.0834735\ttotal: 1m 41s\tremaining: 7m 52s\n",
            "176:\tlearn: 0.0834214\ttotal: 1m 41s\tremaining: 7m 51s\n",
            "177:\tlearn: 0.0833737\ttotal: 1m 41s\tremaining: 7m 50s\n",
            "178:\tlearn: 0.0832760\ttotal: 1m 42s\tremaining: 7m 49s\n",
            "179:\tlearn: 0.0831973\ttotal: 1m 42s\tremaining: 7m 48s\n",
            "180:\tlearn: 0.0831515\ttotal: 1m 43s\tremaining: 7m 47s\n",
            "181:\tlearn: 0.0831268\ttotal: 1m 43s\tremaining: 7m 46s\n",
            "182:\tlearn: 0.0830740\ttotal: 1m 44s\tremaining: 7m 45s\n",
            "183:\tlearn: 0.0830170\ttotal: 1m 44s\tremaining: 7m 44s\n",
            "184:\tlearn: 0.0829473\ttotal: 1m 45s\tremaining: 7m 43s\n",
            "185:\tlearn: 0.0828592\ttotal: 1m 45s\tremaining: 7m 42s\n",
            "186:\tlearn: 0.0827948\ttotal: 1m 46s\tremaining: 7m 43s\n",
            "187:\tlearn: 0.0827637\ttotal: 1m 47s\tremaining: 7m 43s\n",
            "188:\tlearn: 0.0826739\ttotal: 1m 47s\tremaining: 7m 42s\n",
            "189:\tlearn: 0.0826273\ttotal: 1m 48s\tremaining: 7m 41s\n",
            "190:\tlearn: 0.0825461\ttotal: 1m 48s\tremaining: 7m 41s\n",
            "191:\tlearn: 0.0824860\ttotal: 1m 49s\tremaining: 7m 40s\n",
            "192:\tlearn: 0.0824451\ttotal: 1m 49s\tremaining: 7m 38s\n",
            "193:\tlearn: 0.0823814\ttotal: 1m 50s\tremaining: 7m 37s\n",
            "194:\tlearn: 0.0823311\ttotal: 1m 50s\tremaining: 7m 36s\n",
            "195:\tlearn: 0.0822748\ttotal: 1m 51s\tremaining: 7m 35s\n",
            "196:\tlearn: 0.0822267\ttotal: 1m 51s\tremaining: 7m 34s\n",
            "197:\tlearn: 0.0821758\ttotal: 1m 52s\tremaining: 7m 33s\n",
            "198:\tlearn: 0.0821474\ttotal: 1m 52s\tremaining: 7m 32s\n",
            "199:\tlearn: 0.0821057\ttotal: 1m 52s\tremaining: 7m 31s\n",
            "200:\tlearn: 0.0820475\ttotal: 1m 53s\tremaining: 7m 30s\n",
            "201:\tlearn: 0.0819979\ttotal: 1m 53s\tremaining: 7m 29s\n",
            "202:\tlearn: 0.0819660\ttotal: 1m 54s\tremaining: 7m 27s\n",
            "203:\tlearn: 0.0819239\ttotal: 1m 54s\tremaining: 7m 26s\n",
            "204:\tlearn: 0.0818750\ttotal: 1m 54s\tremaining: 7m 25s\n",
            "205:\tlearn: 0.0817958\ttotal: 1m 55s\tremaining: 7m 25s\n",
            "206:\tlearn: 0.0817214\ttotal: 1m 56s\tremaining: 7m 24s\n",
            "207:\tlearn: 0.0816606\ttotal: 1m 56s\tremaining: 7m 23s\n",
            "208:\tlearn: 0.0815500\ttotal: 1m 57s\tremaining: 7m 23s\n",
            "209:\tlearn: 0.0814607\ttotal: 1m 57s\tremaining: 7m 22s\n",
            "210:\tlearn: 0.0814109\ttotal: 1m 58s\tremaining: 7m 21s\n",
            "211:\tlearn: 0.0813416\ttotal: 1m 58s\tremaining: 7m 20s\n",
            "212:\tlearn: 0.0812941\ttotal: 1m 59s\tremaining: 7m 19s\n",
            "213:\tlearn: 0.0812337\ttotal: 1m 59s\tremaining: 7m 19s\n",
            "214:\tlearn: 0.0811662\ttotal: 2m\tremaining: 7m 18s\n",
            "215:\tlearn: 0.0811055\ttotal: 2m\tremaining: 7m 17s\n",
            "216:\tlearn: 0.0810313\ttotal: 2m 1s\tremaining: 7m 16s\n",
            "217:\tlearn: 0.0809366\ttotal: 2m 1s\tremaining: 7m 16s\n",
            "218:\tlearn: 0.0808693\ttotal: 2m 2s\tremaining: 7m 15s\n",
            "219:\tlearn: 0.0808199\ttotal: 2m 2s\tremaining: 7m 14s\n",
            "220:\tlearn: 0.0807829\ttotal: 2m 3s\tremaining: 7m 13s\n",
            "221:\tlearn: 0.0806979\ttotal: 2m 3s\tremaining: 7m 13s\n",
            "222:\tlearn: 0.0806732\ttotal: 2m 3s\tremaining: 7m 11s\n",
            "223:\tlearn: 0.0806026\ttotal: 2m 4s\tremaining: 7m 11s\n",
            "224:\tlearn: 0.0805383\ttotal: 2m 4s\tremaining: 7m 10s\n",
            "225:\tlearn: 0.0804929\ttotal: 2m 5s\tremaining: 7m 9s\n",
            "226:\tlearn: 0.0804595\ttotal: 2m 5s\tremaining: 7m 8s\n",
            "227:\tlearn: 0.0804216\ttotal: 2m 6s\tremaining: 7m 7s\n",
            "228:\tlearn: 0.0803794\ttotal: 2m 6s\tremaining: 7m 6s\n",
            "229:\tlearn: 0.0803550\ttotal: 2m 7s\tremaining: 7m 5s\n",
            "230:\tlearn: 0.0803102\ttotal: 2m 7s\tremaining: 7m 4s\n",
            "231:\tlearn: 0.0802802\ttotal: 2m 7s\tremaining: 7m 3s\n",
            "232:\tlearn: 0.0802101\ttotal: 2m 8s\tremaining: 7m 2s\n",
            "233:\tlearn: 0.0801706\ttotal: 2m 8s\tremaining: 7m 1s\n",
            "234:\tlearn: 0.0801288\ttotal: 2m 9s\tremaining: 7m\n",
            "235:\tlearn: 0.0800821\ttotal: 2m 9s\tremaining: 6m 59s\n",
            "236:\tlearn: 0.0799897\ttotal: 2m 10s\tremaining: 6m 59s\n",
            "237:\tlearn: 0.0799694\ttotal: 2m 10s\tremaining: 6m 58s\n",
            "238:\tlearn: 0.0798925\ttotal: 2m 11s\tremaining: 6m 57s\n",
            "239:\tlearn: 0.0797823\ttotal: 2m 11s\tremaining: 6m 56s\n",
            "240:\tlearn: 0.0797105\ttotal: 2m 12s\tremaining: 6m 56s\n",
            "241:\tlearn: 0.0796490\ttotal: 2m 12s\tremaining: 6m 55s\n",
            "242:\tlearn: 0.0796199\ttotal: 2m 13s\tremaining: 6m 54s\n",
            "243:\tlearn: 0.0796184\ttotal: 2m 13s\tremaining: 6m 53s\n",
            "244:\tlearn: 0.0795623\ttotal: 2m 13s\tremaining: 6m 52s\n",
            "245:\tlearn: 0.0795127\ttotal: 2m 14s\tremaining: 6m 51s\n",
            "246:\tlearn: 0.0794879\ttotal: 2m 14s\tremaining: 6m 50s\n",
            "247:\tlearn: 0.0794527\ttotal: 2m 15s\tremaining: 6m 49s\n",
            "248:\tlearn: 0.0794049\ttotal: 2m 15s\tremaining: 6m 49s\n",
            "249:\tlearn: 0.0793548\ttotal: 2m 16s\tremaining: 6m 48s\n",
            "250:\tlearn: 0.0793052\ttotal: 2m 16s\tremaining: 6m 47s\n",
            "251:\tlearn: 0.0792629\ttotal: 2m 17s\tremaining: 6m 46s\n",
            "252:\tlearn: 0.0791997\ttotal: 2m 17s\tremaining: 6m 45s\n",
            "253:\tlearn: 0.0791690\ttotal: 2m 17s\tremaining: 6m 45s\n",
            "254:\tlearn: 0.0791245\ttotal: 2m 18s\tremaining: 6m 44s\n",
            "255:\tlearn: 0.0790878\ttotal: 2m 19s\tremaining: 6m 45s\n",
            "256:\tlearn: 0.0790502\ttotal: 2m 19s\tremaining: 6m 44s\n",
            "257:\tlearn: 0.0789732\ttotal: 2m 20s\tremaining: 6m 44s\n",
            "258:\tlearn: 0.0789222\ttotal: 2m 21s\tremaining: 6m 44s\n",
            "259:\tlearn: 0.0788878\ttotal: 2m 21s\tremaining: 6m 43s\n",
            "260:\tlearn: 0.0788849\ttotal: 2m 22s\tremaining: 6m 42s\n",
            "261:\tlearn: 0.0788124\ttotal: 2m 22s\tremaining: 6m 41s\n",
            "262:\tlearn: 0.0787730\ttotal: 2m 22s\tremaining: 6m 40s\n",
            "263:\tlearn: 0.0787191\ttotal: 2m 23s\tremaining: 6m 39s\n",
            "264:\tlearn: 0.0786833\ttotal: 2m 23s\tremaining: 6m 38s\n",
            "265:\tlearn: 0.0786193\ttotal: 2m 24s\tremaining: 6m 38s\n",
            "266:\tlearn: 0.0785846\ttotal: 2m 24s\tremaining: 6m 37s\n",
            "267:\tlearn: 0.0785400\ttotal: 2m 25s\tremaining: 6m 36s\n",
            "268:\tlearn: 0.0784286\ttotal: 2m 25s\tremaining: 6m 36s\n",
            "269:\tlearn: 0.0783542\ttotal: 2m 26s\tremaining: 6m 35s\n",
            "270:\tlearn: 0.0782998\ttotal: 2m 26s\tremaining: 6m 35s\n",
            "271:\tlearn: 0.0782812\ttotal: 2m 27s\tremaining: 6m 34s\n",
            "272:\tlearn: 0.0782423\ttotal: 2m 27s\tremaining: 6m 33s\n",
            "273:\tlearn: 0.0782137\ttotal: 2m 28s\tremaining: 6m 32s\n",
            "274:\tlearn: 0.0781275\ttotal: 2m 28s\tremaining: 6m 32s\n",
            "275:\tlearn: 0.0781006\ttotal: 2m 29s\tremaining: 6m 31s\n",
            "276:\tlearn: 0.0780552\ttotal: 2m 29s\tremaining: 6m 30s\n",
            "277:\tlearn: 0.0779642\ttotal: 2m 30s\tremaining: 6m 30s\n",
            "278:\tlearn: 0.0779219\ttotal: 2m 30s\tremaining: 6m 29s\n",
            "279:\tlearn: 0.0778839\ttotal: 2m 31s\tremaining: 6m 28s\n",
            "280:\tlearn: 0.0778432\ttotal: 2m 31s\tremaining: 6m 27s\n",
            "281:\tlearn: 0.0777958\ttotal: 2m 31s\tremaining: 6m 26s\n",
            "282:\tlearn: 0.0777608\ttotal: 2m 32s\tremaining: 6m 25s\n",
            "283:\tlearn: 0.0777491\ttotal: 2m 32s\tremaining: 6m 25s\n",
            "284:\tlearn: 0.0777175\ttotal: 2m 33s\tremaining: 6m 24s\n",
            "285:\tlearn: 0.0776627\ttotal: 2m 33s\tremaining: 6m 23s\n",
            "286:\tlearn: 0.0776232\ttotal: 2m 34s\tremaining: 6m 23s\n",
            "287:\tlearn: 0.0775869\ttotal: 2m 34s\tremaining: 6m 22s\n",
            "288:\tlearn: 0.0775480\ttotal: 2m 35s\tremaining: 6m 21s\n",
            "289:\tlearn: 0.0774909\ttotal: 2m 35s\tremaining: 6m 21s\n",
            "290:\tlearn: 0.0774418\ttotal: 2m 36s\tremaining: 6m 20s\n",
            "291:\tlearn: 0.0774310\ttotal: 2m 36s\tremaining: 6m 19s\n",
            "292:\tlearn: 0.0773822\ttotal: 2m 37s\tremaining: 6m 19s\n",
            "293:\tlearn: 0.0773178\ttotal: 2m 37s\tremaining: 6m 18s\n",
            "294:\tlearn: 0.0772785\ttotal: 2m 38s\tremaining: 6m 18s\n",
            "295:\tlearn: 0.0772618\ttotal: 2m 38s\tremaining: 6m 17s\n",
            "296:\tlearn: 0.0772546\ttotal: 2m 39s\tremaining: 6m 16s\n",
            "297:\tlearn: 0.0772171\ttotal: 2m 39s\tremaining: 6m 15s\n",
            "298:\tlearn: 0.0771684\ttotal: 2m 40s\tremaining: 6m 15s\n",
            "299:\tlearn: 0.0771496\ttotal: 2m 40s\tremaining: 6m 14s\n",
            "300:\tlearn: 0.0771214\ttotal: 2m 40s\tremaining: 6m 13s\n",
            "301:\tlearn: 0.0771016\ttotal: 2m 41s\tremaining: 6m 12s\n",
            "302:\tlearn: 0.0770415\ttotal: 2m 41s\tremaining: 6m 12s\n",
            "303:\tlearn: 0.0770186\ttotal: 2m 42s\tremaining: 6m 11s\n",
            "304:\tlearn: 0.0769597\ttotal: 2m 42s\tremaining: 6m 10s\n",
            "305:\tlearn: 0.0769343\ttotal: 2m 43s\tremaining: 6m 9s\n",
            "306:\tlearn: 0.0768588\ttotal: 2m 43s\tremaining: 6m 9s\n",
            "307:\tlearn: 0.0768362\ttotal: 2m 44s\tremaining: 6m 8s\n",
            "308:\tlearn: 0.0768039\ttotal: 2m 44s\tremaining: 6m 8s\n",
            "309:\tlearn: 0.0767405\ttotal: 2m 45s\tremaining: 6m 7s\n",
            "310:\tlearn: 0.0766986\ttotal: 2m 45s\tremaining: 6m 6s\n",
            "311:\tlearn: 0.0766686\ttotal: 2m 46s\tremaining: 6m 6s\n",
            "312:\tlearn: 0.0766508\ttotal: 2m 46s\tremaining: 6m 5s\n",
            "313:\tlearn: 0.0765893\ttotal: 2m 46s\tremaining: 6m 4s\n",
            "314:\tlearn: 0.0765593\ttotal: 2m 47s\tremaining: 6m 3s\n",
            "315:\tlearn: 0.0765198\ttotal: 2m 47s\tremaining: 6m 3s\n",
            "316:\tlearn: 0.0764768\ttotal: 2m 48s\tremaining: 6m 2s\n",
            "317:\tlearn: 0.0764600\ttotal: 2m 48s\tremaining: 6m 1s\n",
            "318:\tlearn: 0.0764325\ttotal: 2m 49s\tremaining: 6m 1s\n",
            "319:\tlearn: 0.0763147\ttotal: 2m 49s\tremaining: 6m\n",
            "320:\tlearn: 0.0762822\ttotal: 2m 50s\tremaining: 5m 59s\n",
            "321:\tlearn: 0.0762503\ttotal: 2m 50s\tremaining: 5m 58s\n",
            "322:\tlearn: 0.0762196\ttotal: 2m 50s\tremaining: 5m 58s\n",
            "323:\tlearn: 0.0761803\ttotal: 2m 51s\tremaining: 5m 57s\n",
            "324:\tlearn: 0.0761500\ttotal: 2m 51s\tremaining: 5m 56s\n",
            "325:\tlearn: 0.0761235\ttotal: 2m 52s\tremaining: 5m 56s\n",
            "326:\tlearn: 0.0760741\ttotal: 2m 52s\tremaining: 5m 55s\n",
            "327:\tlearn: 0.0760212\ttotal: 2m 53s\tremaining: 5m 55s\n",
            "328:\tlearn: 0.0759936\ttotal: 2m 53s\tremaining: 5m 54s\n",
            "329:\tlearn: 0.0759677\ttotal: 2m 54s\tremaining: 5m 53s\n",
            "330:\tlearn: 0.0759233\ttotal: 2m 54s\tremaining: 5m 53s\n",
            "331:\tlearn: 0.0759096\ttotal: 2m 55s\tremaining: 5m 52s\n",
            "332:\tlearn: 0.0758436\ttotal: 2m 55s\tremaining: 5m 51s\n",
            "333:\tlearn: 0.0758104\ttotal: 2m 56s\tremaining: 5m 51s\n",
            "334:\tlearn: 0.0757828\ttotal: 2m 56s\tremaining: 5m 50s\n",
            "335:\tlearn: 0.0757199\ttotal: 2m 57s\tremaining: 5m 49s\n",
            "336:\tlearn: 0.0756446\ttotal: 2m 57s\tremaining: 5m 49s\n",
            "337:\tlearn: 0.0756183\ttotal: 2m 57s\tremaining: 5m 48s\n",
            "338:\tlearn: 0.0755495\ttotal: 2m 58s\tremaining: 5m 48s\n",
            "339:\tlearn: 0.0754946\ttotal: 2m 59s\tremaining: 5m 47s\n",
            "340:\tlearn: 0.0754608\ttotal: 2m 59s\tremaining: 5m 47s\n",
            "341:\tlearn: 0.0754273\ttotal: 3m\tremaining: 5m 46s\n",
            "342:\tlearn: 0.0753805\ttotal: 3m\tremaining: 5m 45s\n",
            "343:\tlearn: 0.0753445\ttotal: 3m\tremaining: 5m 44s\n",
            "344:\tlearn: 0.0753167\ttotal: 3m 1s\tremaining: 5m 44s\n",
            "345:\tlearn: 0.0752952\ttotal: 3m 1s\tremaining: 5m 43s\n",
            "346:\tlearn: 0.0752573\ttotal: 3m 2s\tremaining: 5m 42s\n",
            "347:\tlearn: 0.0752320\ttotal: 3m 2s\tremaining: 5m 42s\n",
            "348:\tlearn: 0.0751838\ttotal: 3m 3s\tremaining: 5m 41s\n",
            "349:\tlearn: 0.0751421\ttotal: 3m 3s\tremaining: 5m 41s\n",
            "350:\tlearn: 0.0751065\ttotal: 3m 4s\tremaining: 5m 40s\n",
            "351:\tlearn: 0.0750909\ttotal: 3m 4s\tremaining: 5m 39s\n",
            "352:\tlearn: 0.0750280\ttotal: 3m 5s\tremaining: 5m 39s\n",
            "353:\tlearn: 0.0749839\ttotal: 3m 5s\tremaining: 5m 38s\n",
            "354:\tlearn: 0.0749798\ttotal: 3m 5s\tremaining: 5m 37s\n",
            "355:\tlearn: 0.0749118\ttotal: 3m 6s\tremaining: 5m 37s\n",
            "356:\tlearn: 0.0748823\ttotal: 3m 7s\tremaining: 5m 36s\n",
            "357:\tlearn: 0.0748285\ttotal: 3m 7s\tremaining: 5m 36s\n",
            "358:\tlearn: 0.0748069\ttotal: 3m 7s\tremaining: 5m 35s\n",
            "359:\tlearn: 0.0747915\ttotal: 3m 8s\tremaining: 5m 34s\n",
            "360:\tlearn: 0.0747785\ttotal: 3m 8s\tremaining: 5m 33s\n",
            "361:\tlearn: 0.0747482\ttotal: 3m 9s\tremaining: 5m 33s\n",
            "362:\tlearn: 0.0747171\ttotal: 3m 9s\tremaining: 5m 32s\n",
            "363:\tlearn: 0.0746916\ttotal: 3m 9s\tremaining: 5m 31s\n",
            "364:\tlearn: 0.0746350\ttotal: 3m 10s\tremaining: 5m 31s\n",
            "365:\tlearn: 0.0746038\ttotal: 3m 11s\tremaining: 5m 30s\n",
            "366:\tlearn: 0.0745660\ttotal: 3m 11s\tremaining: 5m 30s\n",
            "367:\tlearn: 0.0745093\ttotal: 3m 12s\tremaining: 5m 29s\n",
            "368:\tlearn: 0.0744795\ttotal: 3m 12s\tremaining: 5m 29s\n",
            "369:\tlearn: 0.0744535\ttotal: 3m 12s\tremaining: 5m 28s\n",
            "370:\tlearn: 0.0743874\ttotal: 3m 13s\tremaining: 5m 27s\n",
            "371:\tlearn: 0.0743522\ttotal: 3m 13s\tremaining: 5m 27s\n",
            "372:\tlearn: 0.0743298\ttotal: 3m 14s\tremaining: 5m 26s\n",
            "373:\tlearn: 0.0742944\ttotal: 3m 14s\tremaining: 5m 25s\n",
            "374:\tlearn: 0.0742888\ttotal: 3m 15s\tremaining: 5m 25s\n",
            "375:\tlearn: 0.0742325\ttotal: 3m 15s\tremaining: 5m 24s\n",
            "376:\tlearn: 0.0742112\ttotal: 3m 16s\tremaining: 5m 24s\n",
            "377:\tlearn: 0.0741553\ttotal: 3m 16s\tremaining: 5m 23s\n",
            "378:\tlearn: 0.0740872\ttotal: 3m 17s\tremaining: 5m 23s\n",
            "379:\tlearn: 0.0740663\ttotal: 3m 17s\tremaining: 5m 22s\n",
            "380:\tlearn: 0.0740368\ttotal: 3m 18s\tremaining: 5m 21s\n",
            "381:\tlearn: 0.0739816\ttotal: 3m 18s\tremaining: 5m 21s\n",
            "382:\tlearn: 0.0739288\ttotal: 3m 19s\tremaining: 5m 20s\n",
            "383:\tlearn: 0.0739135\ttotal: 3m 19s\tremaining: 5m 19s\n",
            "384:\tlearn: 0.0738532\ttotal: 3m 19s\tremaining: 5m 19s\n",
            "385:\tlearn: 0.0738186\ttotal: 3m 20s\tremaining: 5m 18s\n",
            "386:\tlearn: 0.0737909\ttotal: 3m 20s\tremaining: 5m 18s\n",
            "387:\tlearn: 0.0737588\ttotal: 3m 21s\tremaining: 5m 17s\n",
            "388:\tlearn: 0.0737425\ttotal: 3m 21s\tremaining: 5m 16s\n",
            "389:\tlearn: 0.0737304\ttotal: 3m 22s\tremaining: 5m 16s\n",
            "390:\tlearn: 0.0736751\ttotal: 3m 22s\tremaining: 5m 15s\n",
            "391:\tlearn: 0.0736397\ttotal: 3m 23s\tremaining: 5m 15s\n",
            "392:\tlearn: 0.0735975\ttotal: 3m 23s\tremaining: 5m 14s\n",
            "393:\tlearn: 0.0735309\ttotal: 3m 24s\tremaining: 5m 14s\n",
            "394:\tlearn: 0.0735110\ttotal: 3m 24s\tremaining: 5m 13s\n",
            "395:\tlearn: 0.0734560\ttotal: 3m 25s\tremaining: 5m 13s\n",
            "396:\tlearn: 0.0734039\ttotal: 3m 26s\tremaining: 5m 12s\n",
            "397:\tlearn: 0.0733684\ttotal: 3m 26s\tremaining: 5m 12s\n",
            "398:\tlearn: 0.0733214\ttotal: 3m 27s\tremaining: 5m 11s\n",
            "399:\tlearn: 0.0733060\ttotal: 3m 27s\tremaining: 5m 11s\n",
            "400:\tlearn: 0.0732846\ttotal: 3m 27s\tremaining: 5m 10s\n",
            "401:\tlearn: 0.0732639\ttotal: 3m 28s\tremaining: 5m 9s\n",
            "402:\tlearn: 0.0732383\ttotal: 3m 28s\tremaining: 5m 9s\n",
            "403:\tlearn: 0.0732157\ttotal: 3m 29s\tremaining: 5m 8s\n",
            "404:\tlearn: 0.0731615\ttotal: 3m 29s\tremaining: 5m 8s\n",
            "405:\tlearn: 0.0731340\ttotal: 3m 30s\tremaining: 5m 7s\n",
            "406:\tlearn: 0.0730859\ttotal: 3m 30s\tremaining: 5m 6s\n",
            "407:\tlearn: 0.0730397\ttotal: 3m 31s\tremaining: 5m 6s\n",
            "408:\tlearn: 0.0730040\ttotal: 3m 31s\tremaining: 5m 5s\n",
            "409:\tlearn: 0.0729944\ttotal: 3m 31s\tremaining: 5m 5s\n",
            "410:\tlearn: 0.0729418\ttotal: 3m 32s\tremaining: 5m 4s\n",
            "411:\tlearn: 0.0728904\ttotal: 3m 33s\tremaining: 5m 4s\n",
            "412:\tlearn: 0.0728744\ttotal: 3m 33s\tremaining: 5m 4s\n",
            "413:\tlearn: 0.0728524\ttotal: 3m 34s\tremaining: 5m 3s\n",
            "414:\tlearn: 0.0728278\ttotal: 3m 34s\tremaining: 5m 2s\n",
            "415:\tlearn: 0.0727787\ttotal: 3m 35s\tremaining: 5m 2s\n",
            "416:\tlearn: 0.0727398\ttotal: 3m 35s\tremaining: 5m 1s\n",
            "417:\tlearn: 0.0726911\ttotal: 3m 36s\tremaining: 5m 1s\n",
            "418:\tlearn: 0.0726660\ttotal: 3m 36s\tremaining: 5m\n",
            "419:\tlearn: 0.0726355\ttotal: 3m 37s\tremaining: 4m 59s\n",
            "420:\tlearn: 0.0725968\ttotal: 3m 37s\tremaining: 4m 59s\n",
            "421:\tlearn: 0.0725486\ttotal: 3m 38s\tremaining: 4m 59s\n",
            "422:\tlearn: 0.0725091\ttotal: 3m 38s\tremaining: 4m 58s\n",
            "423:\tlearn: 0.0724795\ttotal: 3m 39s\tremaining: 4m 57s\n",
            "424:\tlearn: 0.0724450\ttotal: 3m 39s\tremaining: 4m 57s\n",
            "425:\tlearn: 0.0724041\ttotal: 3m 40s\tremaining: 4m 56s\n",
            "426:\tlearn: 0.0723772\ttotal: 3m 40s\tremaining: 4m 55s\n",
            "427:\tlearn: 0.0723575\ttotal: 3m 41s\tremaining: 4m 55s\n",
            "428:\tlearn: 0.0723424\ttotal: 3m 41s\tremaining: 4m 54s\n",
            "429:\tlearn: 0.0723311\ttotal: 3m 41s\tremaining: 4m 54s\n",
            "430:\tlearn: 0.0723067\ttotal: 3m 42s\tremaining: 4m 53s\n",
            "431:\tlearn: 0.0722568\ttotal: 3m 42s\tremaining: 4m 52s\n",
            "432:\tlearn: 0.0722175\ttotal: 3m 43s\tremaining: 4m 52s\n",
            "433:\tlearn: 0.0721462\ttotal: 3m 43s\tremaining: 4m 51s\n",
            "434:\tlearn: 0.0721126\ttotal: 3m 44s\tremaining: 4m 51s\n",
            "435:\tlearn: 0.0720934\ttotal: 3m 44s\tremaining: 4m 50s\n",
            "436:\tlearn: 0.0720543\ttotal: 3m 45s\tremaining: 4m 50s\n",
            "437:\tlearn: 0.0720320\ttotal: 3m 45s\tremaining: 4m 49s\n",
            "438:\tlearn: 0.0719938\ttotal: 3m 46s\tremaining: 4m 49s\n",
            "439:\tlearn: 0.0719706\ttotal: 3m 46s\tremaining: 4m 48s\n",
            "440:\tlearn: 0.0719492\ttotal: 3m 47s\tremaining: 4m 47s\n",
            "441:\tlearn: 0.0719222\ttotal: 3m 47s\tremaining: 4m 47s\n",
            "442:\tlearn: 0.0718678\ttotal: 3m 47s\tremaining: 4m 46s\n",
            "443:\tlearn: 0.0718317\ttotal: 3m 48s\tremaining: 4m 45s\n",
            "444:\tlearn: 0.0718058\ttotal: 3m 48s\tremaining: 4m 45s\n",
            "445:\tlearn: 0.0717860\ttotal: 3m 49s\tremaining: 4m 44s\n",
            "446:\tlearn: 0.0717567\ttotal: 3m 49s\tremaining: 4m 44s\n",
            "447:\tlearn: 0.0717322\ttotal: 3m 50s\tremaining: 4m 43s\n",
            "448:\tlearn: 0.0717018\ttotal: 3m 50s\tremaining: 4m 43s\n",
            "449:\tlearn: 0.0716444\ttotal: 3m 51s\tremaining: 4m 42s\n",
            "450:\tlearn: 0.0716242\ttotal: 3m 51s\tremaining: 4m 41s\n",
            "451:\tlearn: 0.0715788\ttotal: 3m 52s\tremaining: 4m 41s\n",
            "452:\tlearn: 0.0715572\ttotal: 3m 52s\tremaining: 4m 40s\n",
            "453:\tlearn: 0.0715351\ttotal: 3m 52s\tremaining: 4m 40s\n",
            "454:\tlearn: 0.0715090\ttotal: 3m 53s\tremaining: 4m 39s\n",
            "455:\tlearn: 0.0714902\ttotal: 3m 53s\tremaining: 4m 39s\n",
            "456:\tlearn: 0.0714722\ttotal: 3m 54s\tremaining: 4m 38s\n",
            "457:\tlearn: 0.0714490\ttotal: 3m 54s\tremaining: 4m 37s\n",
            "458:\tlearn: 0.0714187\ttotal: 3m 55s\tremaining: 4m 37s\n",
            "459:\tlearn: 0.0713864\ttotal: 3m 55s\tremaining: 4m 36s\n",
            "460:\tlearn: 0.0713068\ttotal: 3m 56s\tremaining: 4m 36s\n",
            "461:\tlearn: 0.0712792\ttotal: 3m 56s\tremaining: 4m 35s\n",
            "462:\tlearn: 0.0712461\ttotal: 3m 57s\tremaining: 4m 35s\n",
            "463:\tlearn: 0.0712245\ttotal: 3m 57s\tremaining: 4m 34s\n",
            "464:\tlearn: 0.0711764\ttotal: 3m 58s\tremaining: 4m 33s\n",
            "465:\tlearn: 0.0711370\ttotal: 3m 58s\tremaining: 4m 33s\n",
            "466:\tlearn: 0.0711151\ttotal: 3m 59s\tremaining: 4m 33s\n",
            "467:\tlearn: 0.0710839\ttotal: 3m 59s\tremaining: 4m 32s\n",
            "468:\tlearn: 0.0710456\ttotal: 4m\tremaining: 4m 31s\n",
            "469:\tlearn: 0.0710181\ttotal: 4m\tremaining: 4m 31s\n",
            "470:\tlearn: 0.0710056\ttotal: 4m\tremaining: 4m 30s\n",
            "471:\tlearn: 0.0709811\ttotal: 4m 1s\tremaining: 4m 30s\n",
            "472:\tlearn: 0.0709488\ttotal: 4m 1s\tremaining: 4m 29s\n",
            "473:\tlearn: 0.0709088\ttotal: 4m 2s\tremaining: 4m 28s\n",
            "474:\tlearn: 0.0708925\ttotal: 4m 2s\tremaining: 4m 28s\n",
            "475:\tlearn: 0.0708583\ttotal: 4m 3s\tremaining: 4m 27s\n",
            "476:\tlearn: 0.0708341\ttotal: 4m 3s\tremaining: 4m 27s\n",
            "477:\tlearn: 0.0708170\ttotal: 4m 4s\tremaining: 4m 26s\n",
            "478:\tlearn: 0.0707776\ttotal: 4m 4s\tremaining: 4m 26s\n",
            "479:\tlearn: 0.0707616\ttotal: 4m 5s\tremaining: 4m 25s\n",
            "480:\tlearn: 0.0707531\ttotal: 4m 6s\tremaining: 4m 25s\n",
            "481:\tlearn: 0.0707206\ttotal: 4m 6s\tremaining: 4m 25s\n",
            "482:\tlearn: 0.0707046\ttotal: 4m 7s\tremaining: 4m 24s\n",
            "483:\tlearn: 0.0706945\ttotal: 4m 7s\tremaining: 4m 23s\n",
            "484:\tlearn: 0.0706481\ttotal: 4m 7s\tremaining: 4m 23s\n",
            "485:\tlearn: 0.0706305\ttotal: 4m 8s\tremaining: 4m 22s\n",
            "486:\tlearn: 0.0705893\ttotal: 4m 8s\tremaining: 4m 22s\n",
            "487:\tlearn: 0.0705689\ttotal: 4m 9s\tremaining: 4m 21s\n",
            "488:\tlearn: 0.0705420\ttotal: 4m 9s\tremaining: 4m 20s\n",
            "489:\tlearn: 0.0704999\ttotal: 4m 10s\tremaining: 4m 20s\n",
            "490:\tlearn: 0.0704977\ttotal: 4m 10s\tremaining: 4m 19s\n",
            "491:\tlearn: 0.0704862\ttotal: 4m 10s\tremaining: 4m 19s\n",
            "492:\tlearn: 0.0704566\ttotal: 4m 11s\tremaining: 4m 18s\n",
            "493:\tlearn: 0.0704339\ttotal: 4m 11s\tremaining: 4m 18s\n",
            "494:\tlearn: 0.0704146\ttotal: 4m 12s\tremaining: 4m 17s\n",
            "495:\tlearn: 0.0703919\ttotal: 4m 12s\tremaining: 4m 16s\n",
            "496:\tlearn: 0.0703425\ttotal: 4m 13s\tremaining: 4m 16s\n",
            "497:\tlearn: 0.0703249\ttotal: 4m 13s\tremaining: 4m 15s\n",
            "498:\tlearn: 0.0702960\ttotal: 4m 14s\tremaining: 4m 15s\n",
            "499:\tlearn: 0.0702885\ttotal: 4m 14s\tremaining: 4m 14s\n",
            "500:\tlearn: 0.0702788\ttotal: 4m 15s\tremaining: 4m 14s\n",
            "501:\tlearn: 0.0702509\ttotal: 4m 15s\tremaining: 4m 13s\n",
            "502:\tlearn: 0.0702248\ttotal: 4m 16s\tremaining: 4m 12s\n",
            "503:\tlearn: 0.0701926\ttotal: 4m 16s\tremaining: 4m 12s\n",
            "504:\tlearn: 0.0701911\ttotal: 4m 17s\tremaining: 4m 11s\n",
            "505:\tlearn: 0.0701543\ttotal: 4m 17s\tremaining: 4m 11s\n",
            "506:\tlearn: 0.0701472\ttotal: 4m 18s\tremaining: 4m 10s\n",
            "507:\tlearn: 0.0701050\ttotal: 4m 18s\tremaining: 4m 10s\n",
            "508:\tlearn: 0.0700529\ttotal: 4m 19s\tremaining: 4m 9s\n",
            "509:\tlearn: 0.0700377\ttotal: 4m 19s\tremaining: 4m 9s\n",
            "510:\tlearn: 0.0699806\ttotal: 4m 19s\tremaining: 4m 8s\n",
            "511:\tlearn: 0.0699634\ttotal: 4m 20s\tremaining: 4m 8s\n",
            "512:\tlearn: 0.0699318\ttotal: 4m 20s\tremaining: 4m 7s\n",
            "513:\tlearn: 0.0699185\ttotal: 4m 21s\tremaining: 4m 7s\n",
            "514:\tlearn: 0.0698977\ttotal: 4m 21s\tremaining: 4m 6s\n",
            "515:\tlearn: 0.0698618\ttotal: 4m 22s\tremaining: 4m 5s\n",
            "516:\tlearn: 0.0698221\ttotal: 4m 22s\tremaining: 4m 5s\n",
            "517:\tlearn: 0.0697827\ttotal: 4m 23s\tremaining: 4m 4s\n",
            "518:\tlearn: 0.0697490\ttotal: 4m 23s\tremaining: 4m 4s\n",
            "519:\tlearn: 0.0697238\ttotal: 4m 24s\tremaining: 4m 3s\n",
            "520:\tlearn: 0.0696997\ttotal: 4m 24s\tremaining: 4m 3s\n",
            "521:\tlearn: 0.0696882\ttotal: 4m 24s\tremaining: 4m 2s\n",
            "522:\tlearn: 0.0696741\ttotal: 4m 25s\tremaining: 4m 1s\n",
            "523:\tlearn: 0.0696510\ttotal: 4m 25s\tremaining: 4m 1s\n",
            "524:\tlearn: 0.0696303\ttotal: 4m 26s\tremaining: 4m\n",
            "525:\tlearn: 0.0696030\ttotal: 4m 26s\tremaining: 4m\n",
            "526:\tlearn: 0.0695971\ttotal: 4m 27s\tremaining: 3m 59s\n",
            "527:\tlearn: 0.0695584\ttotal: 4m 27s\tremaining: 3m 59s\n",
            "528:\tlearn: 0.0695347\ttotal: 4m 28s\tremaining: 3m 58s\n",
            "529:\tlearn: 0.0695305\ttotal: 4m 28s\tremaining: 3m 58s\n",
            "530:\tlearn: 0.0694790\ttotal: 4m 29s\tremaining: 3m 57s\n",
            "531:\tlearn: 0.0694691\ttotal: 4m 29s\tremaining: 3m 57s\n",
            "532:\tlearn: 0.0694242\ttotal: 4m 30s\tremaining: 3m 56s\n",
            "533:\tlearn: 0.0694138\ttotal: 4m 30s\tremaining: 3m 56s\n",
            "534:\tlearn: 0.0693726\ttotal: 4m 30s\tremaining: 3m 55s\n",
            "535:\tlearn: 0.0693433\ttotal: 4m 31s\tremaining: 3m 54s\n",
            "536:\tlearn: 0.0693249\ttotal: 4m 31s\tremaining: 3m 54s\n",
            "537:\tlearn: 0.0692988\ttotal: 4m 32s\tremaining: 3m 53s\n",
            "538:\tlearn: 0.0692569\ttotal: 4m 32s\tremaining: 3m 53s\n",
            "539:\tlearn: 0.0692288\ttotal: 4m 33s\tremaining: 3m 52s\n",
            "540:\tlearn: 0.0691881\ttotal: 4m 33s\tremaining: 3m 52s\n",
            "541:\tlearn: 0.0691602\ttotal: 4m 34s\tremaining: 3m 51s\n",
            "542:\tlearn: 0.0691253\ttotal: 4m 34s\tremaining: 3m 51s\n",
            "543:\tlearn: 0.0690993\ttotal: 4m 35s\tremaining: 3m 50s\n",
            "544:\tlearn: 0.0690859\ttotal: 4m 35s\tremaining: 3m 50s\n",
            "545:\tlearn: 0.0690486\ttotal: 4m 35s\tremaining: 3m 49s\n",
            "546:\tlearn: 0.0690342\ttotal: 4m 36s\tremaining: 3m 48s\n",
            "547:\tlearn: 0.0690254\ttotal: 4m 36s\tremaining: 3m 48s\n",
            "548:\tlearn: 0.0690054\ttotal: 4m 37s\tremaining: 3m 47s\n",
            "549:\tlearn: 0.0689947\ttotal: 4m 37s\tremaining: 3m 47s\n",
            "550:\tlearn: 0.0689782\ttotal: 4m 38s\tremaining: 3m 46s\n",
            "551:\tlearn: 0.0689758\ttotal: 4m 38s\tremaining: 3m 46s\n",
            "552:\tlearn: 0.0689649\ttotal: 4m 38s\tremaining: 3m 45s\n",
            "553:\tlearn: 0.0689392\ttotal: 4m 39s\tremaining: 3m 44s\n",
            "554:\tlearn: 0.0689162\ttotal: 4m 39s\tremaining: 3m 44s\n",
            "555:\tlearn: 0.0688726\ttotal: 4m 40s\tremaining: 3m 44s\n",
            "556:\tlearn: 0.0688440\ttotal: 4m 41s\tremaining: 3m 43s\n",
            "557:\tlearn: 0.0688112\ttotal: 4m 41s\tremaining: 3m 42s\n",
            "558:\tlearn: 0.0687888\ttotal: 4m 42s\tremaining: 3m 42s\n",
            "559:\tlearn: 0.0687813\ttotal: 4m 42s\tremaining: 3m 41s\n",
            "560:\tlearn: 0.0687548\ttotal: 4m 42s\tremaining: 3m 41s\n",
            "561:\tlearn: 0.0687501\ttotal: 4m 43s\tremaining: 3m 40s\n",
            "562:\tlearn: 0.0687062\ttotal: 4m 43s\tremaining: 3m 40s\n",
            "563:\tlearn: 0.0686726\ttotal: 4m 44s\tremaining: 3m 39s\n",
            "564:\tlearn: 0.0686665\ttotal: 4m 44s\tremaining: 3m 39s\n",
            "565:\tlearn: 0.0686504\ttotal: 4m 45s\tremaining: 3m 38s\n",
            "566:\tlearn: 0.0686287\ttotal: 4m 45s\tremaining: 3m 38s\n",
            "567:\tlearn: 0.0686138\ttotal: 4m 46s\tremaining: 3m 37s\n",
            "568:\tlearn: 0.0685799\ttotal: 4m 46s\tremaining: 3m 37s\n",
            "569:\tlearn: 0.0685506\ttotal: 4m 47s\tremaining: 3m 36s\n",
            "570:\tlearn: 0.0685316\ttotal: 4m 47s\tremaining: 3m 36s\n",
            "571:\tlearn: 0.0685206\ttotal: 4m 48s\tremaining: 3m 35s\n",
            "572:\tlearn: 0.0684910\ttotal: 4m 48s\tremaining: 3m 35s\n",
            "573:\tlearn: 0.0684700\ttotal: 4m 49s\tremaining: 3m 34s\n",
            "574:\tlearn: 0.0684417\ttotal: 4m 49s\tremaining: 3m 33s\n",
            "575:\tlearn: 0.0684091\ttotal: 4m 49s\tremaining: 3m 33s\n",
            "576:\tlearn: 0.0683937\ttotal: 4m 50s\tremaining: 3m 32s\n",
            "577:\tlearn: 0.0683641\ttotal: 4m 50s\tremaining: 3m 32s\n",
            "578:\tlearn: 0.0683371\ttotal: 4m 51s\tremaining: 3m 31s\n",
            "579:\tlearn: 0.0683158\ttotal: 4m 51s\tremaining: 3m 31s\n",
            "580:\tlearn: 0.0682849\ttotal: 4m 52s\tremaining: 3m 30s\n",
            "581:\tlearn: 0.0682660\ttotal: 4m 52s\tremaining: 3m 30s\n",
            "582:\tlearn: 0.0682557\ttotal: 4m 53s\tremaining: 3m 29s\n",
            "583:\tlearn: 0.0682180\ttotal: 4m 53s\tremaining: 3m 29s\n",
            "584:\tlearn: 0.0681925\ttotal: 4m 54s\tremaining: 3m 28s\n",
            "585:\tlearn: 0.0681726\ttotal: 4m 54s\tremaining: 3m 28s\n",
            "586:\tlearn: 0.0681517\ttotal: 4m 55s\tremaining: 3m 27s\n",
            "587:\tlearn: 0.0681338\ttotal: 4m 55s\tremaining: 3m 27s\n",
            "588:\tlearn: 0.0681187\ttotal: 4m 56s\tremaining: 3m 26s\n",
            "589:\tlearn: 0.0680915\ttotal: 4m 56s\tremaining: 3m 26s\n",
            "590:\tlearn: 0.0680765\ttotal: 4m 56s\tremaining: 3m 25s\n",
            "591:\tlearn: 0.0680209\ttotal: 4m 57s\tremaining: 3m 24s\n",
            "592:\tlearn: 0.0679639\ttotal: 4m 57s\tremaining: 3m 24s\n",
            "593:\tlearn: 0.0679499\ttotal: 4m 58s\tremaining: 3m 23s\n",
            "594:\tlearn: 0.0679305\ttotal: 4m 58s\tremaining: 3m 23s\n",
            "595:\tlearn: 0.0679147\ttotal: 4m 59s\tremaining: 3m 22s\n",
            "596:\tlearn: 0.0678930\ttotal: 4m 59s\tremaining: 3m 22s\n",
            "597:\tlearn: 0.0678780\ttotal: 5m\tremaining: 3m 21s\n",
            "598:\tlearn: 0.0678539\ttotal: 5m\tremaining: 3m 21s\n",
            "599:\tlearn: 0.0678157\ttotal: 5m 1s\tremaining: 3m 20s\n",
            "600:\tlearn: 0.0677969\ttotal: 5m 1s\tremaining: 3m 20s\n",
            "601:\tlearn: 0.0677886\ttotal: 5m 2s\tremaining: 3m 19s\n",
            "602:\tlearn: 0.0677557\ttotal: 5m 2s\tremaining: 3m 19s\n",
            "603:\tlearn: 0.0677123\ttotal: 5m 3s\tremaining: 3m 18s\n",
            "604:\tlearn: 0.0677009\ttotal: 5m 3s\tremaining: 3m 18s\n",
            "605:\tlearn: 0.0676834\ttotal: 5m 4s\tremaining: 3m 17s\n",
            "606:\tlearn: 0.0676547\ttotal: 5m 4s\tremaining: 3m 17s\n",
            "607:\tlearn: 0.0676227\ttotal: 5m 5s\tremaining: 3m 16s\n",
            "608:\tlearn: 0.0675976\ttotal: 5m 5s\tremaining: 3m 16s\n",
            "609:\tlearn: 0.0675909\ttotal: 5m 6s\tremaining: 3m 15s\n",
            "610:\tlearn: 0.0675737\ttotal: 5m 6s\tremaining: 3m 15s\n",
            "611:\tlearn: 0.0675459\ttotal: 5m 7s\tremaining: 3m 14s\n",
            "612:\tlearn: 0.0675134\ttotal: 5m 7s\tremaining: 3m 14s\n",
            "613:\tlearn: 0.0674741\ttotal: 5m 8s\tremaining: 3m 13s\n",
            "614:\tlearn: 0.0674515\ttotal: 5m 8s\tremaining: 3m 13s\n",
            "615:\tlearn: 0.0674288\ttotal: 5m 9s\tremaining: 3m 12s\n",
            "616:\tlearn: 0.0674140\ttotal: 5m 9s\tremaining: 3m 12s\n",
            "617:\tlearn: 0.0674008\ttotal: 5m 9s\tremaining: 3m 11s\n",
            "618:\tlearn: 0.0673621\ttotal: 5m 10s\tremaining: 3m 11s\n",
            "619:\tlearn: 0.0673418\ttotal: 5m 10s\tremaining: 3m 10s\n",
            "620:\tlearn: 0.0673039\ttotal: 5m 11s\tremaining: 3m 10s\n",
            "621:\tlearn: 0.0673025\ttotal: 5m 11s\tremaining: 3m 9s\n",
            "622:\tlearn: 0.0672781\ttotal: 5m 12s\tremaining: 3m 9s\n",
            "623:\tlearn: 0.0672610\ttotal: 5m 12s\tremaining: 3m 8s\n",
            "624:\tlearn: 0.0672360\ttotal: 5m 13s\tremaining: 3m 8s\n",
            "625:\tlearn: 0.0671903\ttotal: 5m 14s\tremaining: 3m 7s\n",
            "626:\tlearn: 0.0671651\ttotal: 5m 14s\tremaining: 3m 7s\n",
            "627:\tlearn: 0.0671458\ttotal: 5m 14s\tremaining: 3m 6s\n",
            "628:\tlearn: 0.0671131\ttotal: 5m 15s\tremaining: 3m 6s\n",
            "629:\tlearn: 0.0670623\ttotal: 5m 16s\tremaining: 3m 5s\n",
            "630:\tlearn: 0.0670561\ttotal: 5m 16s\tremaining: 3m 5s\n",
            "631:\tlearn: 0.0670424\ttotal: 5m 16s\tremaining: 3m 4s\n",
            "632:\tlearn: 0.0670233\ttotal: 5m 17s\tremaining: 3m 3s\n",
            "633:\tlearn: 0.0669941\ttotal: 5m 17s\tremaining: 3m 3s\n",
            "634:\tlearn: 0.0669756\ttotal: 5m 18s\tremaining: 3m 2s\n",
            "635:\tlearn: 0.0669433\ttotal: 5m 18s\tremaining: 3m 2s\n",
            "636:\tlearn: 0.0669391\ttotal: 5m 19s\tremaining: 3m 1s\n",
            "637:\tlearn: 0.0669241\ttotal: 5m 19s\tremaining: 3m 1s\n",
            "638:\tlearn: 0.0669108\ttotal: 5m 20s\tremaining: 3m 1s\n",
            "639:\tlearn: 0.0668895\ttotal: 5m 20s\tremaining: 3m\n",
            "640:\tlearn: 0.0668889\ttotal: 5m 21s\tremaining: 2m 59s\n",
            "641:\tlearn: 0.0668504\ttotal: 5m 21s\tremaining: 2m 59s\n",
            "642:\tlearn: 0.0668227\ttotal: 5m 22s\tremaining: 2m 58s\n",
            "643:\tlearn: 0.0668072\ttotal: 5m 22s\tremaining: 2m 58s\n",
            "644:\tlearn: 0.0668023\ttotal: 5m 23s\tremaining: 2m 57s\n",
            "645:\tlearn: 0.0667803\ttotal: 5m 23s\tremaining: 2m 57s\n",
            "646:\tlearn: 0.0667773\ttotal: 5m 24s\tremaining: 2m 56s\n",
            "647:\tlearn: 0.0667632\ttotal: 5m 24s\tremaining: 2m 56s\n",
            "648:\tlearn: 0.0667452\ttotal: 5m 24s\tremaining: 2m 55s\n",
            "649:\tlearn: 0.0667178\ttotal: 5m 25s\tremaining: 2m 55s\n",
            "650:\tlearn: 0.0667042\ttotal: 5m 25s\tremaining: 2m 54s\n",
            "651:\tlearn: 0.0666828\ttotal: 5m 26s\tremaining: 2m 54s\n",
            "652:\tlearn: 0.0666500\ttotal: 5m 26s\tremaining: 2m 53s\n",
            "653:\tlearn: 0.0666280\ttotal: 5m 27s\tremaining: 2m 53s\n",
            "654:\tlearn: 0.0666065\ttotal: 5m 27s\tremaining: 2m 52s\n",
            "655:\tlearn: 0.0665977\ttotal: 5m 28s\tremaining: 2m 52s\n",
            "656:\tlearn: 0.0665637\ttotal: 5m 28s\tremaining: 2m 51s\n",
            "657:\tlearn: 0.0665377\ttotal: 5m 29s\tremaining: 2m 51s\n",
            "658:\tlearn: 0.0665231\ttotal: 5m 29s\tremaining: 2m 50s\n",
            "659:\tlearn: 0.0665025\ttotal: 5m 30s\tremaining: 2m 50s\n",
            "660:\tlearn: 0.0664496\ttotal: 5m 30s\tremaining: 2m 49s\n",
            "661:\tlearn: 0.0664428\ttotal: 5m 30s\tremaining: 2m 48s\n",
            "662:\tlearn: 0.0664190\ttotal: 5m 31s\tremaining: 2m 48s\n",
            "663:\tlearn: 0.0664070\ttotal: 5m 31s\tremaining: 2m 47s\n",
            "664:\tlearn: 0.0663828\ttotal: 5m 32s\tremaining: 2m 47s\n",
            "665:\tlearn: 0.0663519\ttotal: 5m 32s\tremaining: 2m 46s\n",
            "666:\tlearn: 0.0663351\ttotal: 5m 33s\tremaining: 2m 46s\n",
            "667:\tlearn: 0.0663105\ttotal: 5m 33s\tremaining: 2m 45s\n",
            "668:\tlearn: 0.0662989\ttotal: 5m 34s\tremaining: 2m 45s\n",
            "669:\tlearn: 0.0662863\ttotal: 5m 34s\tremaining: 2m 44s\n",
            "670:\tlearn: 0.0662833\ttotal: 5m 35s\tremaining: 2m 44s\n",
            "671:\tlearn: 0.0662629\ttotal: 5m 35s\tremaining: 2m 43s\n",
            "672:\tlearn: 0.0662240\ttotal: 5m 35s\tremaining: 2m 43s\n",
            "673:\tlearn: 0.0662076\ttotal: 5m 36s\tremaining: 2m 42s\n",
            "674:\tlearn: 0.0661975\ttotal: 5m 36s\tremaining: 2m 42s\n",
            "675:\tlearn: 0.0661885\ttotal: 5m 37s\tremaining: 2m 41s\n",
            "676:\tlearn: 0.0661725\ttotal: 5m 37s\tremaining: 2m 41s\n",
            "677:\tlearn: 0.0661646\ttotal: 5m 38s\tremaining: 2m 40s\n",
            "678:\tlearn: 0.0661418\ttotal: 5m 38s\tremaining: 2m 40s\n",
            "679:\tlearn: 0.0661008\ttotal: 5m 39s\tremaining: 2m 39s\n",
            "680:\tlearn: 0.0660893\ttotal: 5m 39s\tremaining: 2m 39s\n",
            "681:\tlearn: 0.0660677\ttotal: 5m 40s\tremaining: 2m 38s\n",
            "682:\tlearn: 0.0660300\ttotal: 5m 40s\tremaining: 2m 38s\n",
            "683:\tlearn: 0.0659823\ttotal: 5m 41s\tremaining: 2m 37s\n",
            "684:\tlearn: 0.0659672\ttotal: 5m 41s\tremaining: 2m 37s\n",
            "685:\tlearn: 0.0659245\ttotal: 5m 42s\tremaining: 2m 36s\n",
            "686:\tlearn: 0.0658871\ttotal: 5m 42s\tremaining: 2m 36s\n",
            "687:\tlearn: 0.0658427\ttotal: 5m 43s\tremaining: 2m 35s\n",
            "688:\tlearn: 0.0658352\ttotal: 5m 43s\tremaining: 2m 35s\n",
            "689:\tlearn: 0.0658019\ttotal: 5m 44s\tremaining: 2m 34s\n",
            "690:\tlearn: 0.0657937\ttotal: 5m 44s\tremaining: 2m 34s\n",
            "691:\tlearn: 0.0657598\ttotal: 5m 45s\tremaining: 2m 33s\n",
            "692:\tlearn: 0.0657335\ttotal: 5m 46s\tremaining: 2m 33s\n",
            "693:\tlearn: 0.0657106\ttotal: 5m 46s\tremaining: 2m 32s\n",
            "694:\tlearn: 0.0656893\ttotal: 5m 47s\tremaining: 2m 32s\n",
            "695:\tlearn: 0.0656474\ttotal: 5m 47s\tremaining: 2m 31s\n",
            "696:\tlearn: 0.0656413\ttotal: 5m 47s\tremaining: 2m 31s\n",
            "697:\tlearn: 0.0656151\ttotal: 5m 48s\tremaining: 2m 30s\n",
            "698:\tlearn: 0.0656122\ttotal: 5m 48s\tremaining: 2m 30s\n",
            "699:\tlearn: 0.0655701\ttotal: 5m 49s\tremaining: 2m 29s\n",
            "700:\tlearn: 0.0655417\ttotal: 5m 49s\tremaining: 2m 29s\n",
            "701:\tlearn: 0.0655261\ttotal: 5m 50s\tremaining: 2m 28s\n",
            "702:\tlearn: 0.0655207\ttotal: 5m 50s\tremaining: 2m 28s\n",
            "703:\tlearn: 0.0655094\ttotal: 5m 51s\tremaining: 2m 27s\n",
            "704:\tlearn: 0.0654773\ttotal: 5m 51s\tremaining: 2m 27s\n",
            "705:\tlearn: 0.0654353\ttotal: 5m 52s\tremaining: 2m 26s\n",
            "706:\tlearn: 0.0654231\ttotal: 5m 53s\tremaining: 2m 26s\n",
            "707:\tlearn: 0.0654080\ttotal: 5m 53s\tremaining: 2m 25s\n",
            "708:\tlearn: 0.0653348\ttotal: 5m 54s\tremaining: 2m 25s\n",
            "709:\tlearn: 0.0653296\ttotal: 5m 54s\tremaining: 2m 24s\n",
            "710:\tlearn: 0.0653083\ttotal: 5m 55s\tremaining: 2m 24s\n",
            "711:\tlearn: 0.0653065\ttotal: 5m 55s\tremaining: 2m 23s\n",
            "712:\tlearn: 0.0652511\ttotal: 5m 56s\tremaining: 2m 23s\n",
            "713:\tlearn: 0.0652244\ttotal: 5m 56s\tremaining: 2m 22s\n",
            "714:\tlearn: 0.0651806\ttotal: 5m 57s\tremaining: 2m 22s\n",
            "715:\tlearn: 0.0651715\ttotal: 5m 57s\tremaining: 2m 21s\n",
            "716:\tlearn: 0.0651642\ttotal: 5m 58s\tremaining: 2m 21s\n",
            "717:\tlearn: 0.0651429\ttotal: 5m 58s\tremaining: 2m 20s\n",
            "718:\tlearn: 0.0651199\ttotal: 5m 59s\tremaining: 2m 20s\n",
            "719:\tlearn: 0.0651160\ttotal: 5m 59s\tremaining: 2m 19s\n",
            "720:\tlearn: 0.0650872\ttotal: 6m\tremaining: 2m 19s\n",
            "721:\tlearn: 0.0650691\ttotal: 6m\tremaining: 2m 18s\n",
            "722:\tlearn: 0.0650626\ttotal: 6m\tremaining: 2m 18s\n",
            "723:\tlearn: 0.0650407\ttotal: 6m 1s\tremaining: 2m 17s\n",
            "724:\tlearn: 0.0650185\ttotal: 6m 1s\tremaining: 2m 17s\n",
            "725:\tlearn: 0.0650125\ttotal: 6m 2s\tremaining: 2m 16s\n",
            "726:\tlearn: 0.0650081\ttotal: 6m 2s\tremaining: 2m 16s\n",
            "727:\tlearn: 0.0649808\ttotal: 6m 3s\tremaining: 2m 15s\n",
            "728:\tlearn: 0.0649633\ttotal: 6m 3s\tremaining: 2m 15s\n",
            "729:\tlearn: 0.0649630\ttotal: 6m 3s\tremaining: 2m 14s\n",
            "730:\tlearn: 0.0649476\ttotal: 6m 4s\tremaining: 2m 14s\n",
            "731:\tlearn: 0.0648905\ttotal: 6m 4s\tremaining: 2m 13s\n",
            "732:\tlearn: 0.0648767\ttotal: 6m 5s\tremaining: 2m 13s\n",
            "733:\tlearn: 0.0648459\ttotal: 6m 5s\tremaining: 2m 12s\n",
            "734:\tlearn: 0.0648243\ttotal: 6m 6s\tremaining: 2m 12s\n",
            "735:\tlearn: 0.0647634\ttotal: 6m 7s\tremaining: 2m 11s\n",
            "736:\tlearn: 0.0647211\ttotal: 6m 7s\tremaining: 2m 11s\n",
            "737:\tlearn: 0.0646780\ttotal: 6m 8s\tremaining: 2m 10s\n",
            "738:\tlearn: 0.0646611\ttotal: 6m 8s\tremaining: 2m 10s\n",
            "739:\tlearn: 0.0646478\ttotal: 6m 9s\tremaining: 2m 9s\n",
            "740:\tlearn: 0.0646234\ttotal: 6m 9s\tremaining: 2m 9s\n",
            "741:\tlearn: 0.0646141\ttotal: 6m 10s\tremaining: 2m 8s\n",
            "742:\tlearn: 0.0645992\ttotal: 6m 10s\tremaining: 2m 8s\n",
            "743:\tlearn: 0.0645777\ttotal: 6m 10s\tremaining: 2m 7s\n",
            "744:\tlearn: 0.0645608\ttotal: 6m 11s\tremaining: 2m 7s\n",
            "745:\tlearn: 0.0645491\ttotal: 6m 11s\tremaining: 2m 6s\n",
            "746:\tlearn: 0.0645167\ttotal: 6m 12s\tremaining: 2m 6s\n",
            "747:\tlearn: 0.0644699\ttotal: 6m 13s\tremaining: 2m 5s\n",
            "748:\tlearn: 0.0644412\ttotal: 6m 13s\tremaining: 2m 5s\n",
            "749:\tlearn: 0.0644301\ttotal: 6m 13s\tremaining: 2m 4s\n",
            "750:\tlearn: 0.0644249\ttotal: 6m 14s\tremaining: 2m 4s\n",
            "751:\tlearn: 0.0643974\ttotal: 6m 14s\tremaining: 2m 3s\n",
            "752:\tlearn: 0.0643893\ttotal: 6m 15s\tremaining: 2m 3s\n",
            "753:\tlearn: 0.0643126\ttotal: 6m 15s\tremaining: 2m 2s\n",
            "754:\tlearn: 0.0642740\ttotal: 6m 16s\tremaining: 2m 2s\n",
            "755:\tlearn: 0.0642683\ttotal: 6m 16s\tremaining: 2m 1s\n",
            "756:\tlearn: 0.0642495\ttotal: 6m 16s\tremaining: 2m\n",
            "757:\tlearn: 0.0642450\ttotal: 6m 17s\tremaining: 2m\n",
            "758:\tlearn: 0.0642312\ttotal: 6m 17s\tremaining: 1m 59s\n",
            "759:\tlearn: 0.0641938\ttotal: 6m 18s\tremaining: 1m 59s\n",
            "760:\tlearn: 0.0641824\ttotal: 6m 18s\tremaining: 1m 59s\n",
            "761:\tlearn: 0.0641598\ttotal: 6m 19s\tremaining: 1m 58s\n",
            "762:\tlearn: 0.0641461\ttotal: 6m 19s\tremaining: 1m 57s\n",
            "763:\tlearn: 0.0641089\ttotal: 6m 20s\tremaining: 1m 57s\n",
            "764:\tlearn: 0.0641038\ttotal: 6m 20s\tremaining: 1m 57s\n",
            "765:\tlearn: 0.0641009\ttotal: 6m 21s\tremaining: 1m 56s\n",
            "766:\tlearn: 0.0640749\ttotal: 6m 21s\tremaining: 1m 55s\n",
            "767:\tlearn: 0.0640547\ttotal: 6m 22s\tremaining: 1m 55s\n",
            "768:\tlearn: 0.0640344\ttotal: 6m 22s\tremaining: 1m 54s\n",
            "769:\tlearn: 0.0639973\ttotal: 6m 23s\tremaining: 1m 54s\n",
            "770:\tlearn: 0.0639713\ttotal: 6m 23s\tremaining: 1m 53s\n",
            "771:\tlearn: 0.0639382\ttotal: 6m 24s\tremaining: 1m 53s\n",
            "772:\tlearn: 0.0639343\ttotal: 6m 24s\tremaining: 1m 52s\n",
            "773:\tlearn: 0.0638908\ttotal: 6m 25s\tremaining: 1m 52s\n",
            "774:\tlearn: 0.0638812\ttotal: 6m 25s\tremaining: 1m 51s\n",
            "775:\tlearn: 0.0638715\ttotal: 6m 26s\tremaining: 1m 51s\n",
            "776:\tlearn: 0.0638684\ttotal: 6m 26s\tremaining: 1m 50s\n",
            "777:\tlearn: 0.0638430\ttotal: 6m 27s\tremaining: 1m 50s\n",
            "778:\tlearn: 0.0638272\ttotal: 6m 27s\tremaining: 1m 49s\n",
            "779:\tlearn: 0.0638173\ttotal: 6m 27s\tremaining: 1m 49s\n",
            "780:\tlearn: 0.0638146\ttotal: 6m 28s\tremaining: 1m 48s\n",
            "781:\tlearn: 0.0637965\ttotal: 6m 28s\tremaining: 1m 48s\n",
            "782:\tlearn: 0.0637903\ttotal: 6m 29s\tremaining: 1m 47s\n",
            "783:\tlearn: 0.0637674\ttotal: 6m 29s\tremaining: 1m 47s\n",
            "784:\tlearn: 0.0637582\ttotal: 6m 30s\tremaining: 1m 46s\n",
            "785:\tlearn: 0.0637379\ttotal: 6m 30s\tremaining: 1m 46s\n",
            "786:\tlearn: 0.0637320\ttotal: 6m 30s\tremaining: 1m 45s\n",
            "787:\tlearn: 0.0637258\ttotal: 6m 31s\tremaining: 1m 45s\n",
            "788:\tlearn: 0.0636823\ttotal: 6m 31s\tremaining: 1m 44s\n",
            "789:\tlearn: 0.0636513\ttotal: 6m 32s\tremaining: 1m 44s\n",
            "790:\tlearn: 0.0636407\ttotal: 6m 32s\tremaining: 1m 43s\n",
            "791:\tlearn: 0.0636358\ttotal: 6m 33s\tremaining: 1m 43s\n",
            "792:\tlearn: 0.0636204\ttotal: 6m 33s\tremaining: 1m 42s\n",
            "793:\tlearn: 0.0635987\ttotal: 6m 34s\tremaining: 1m 42s\n",
            "794:\tlearn: 0.0635862\ttotal: 6m 34s\tremaining: 1m 41s\n",
            "795:\tlearn: 0.0635646\ttotal: 6m 34s\tremaining: 1m 41s\n",
            "796:\tlearn: 0.0635486\ttotal: 6m 35s\tremaining: 1m 40s\n",
            "797:\tlearn: 0.0635319\ttotal: 6m 35s\tremaining: 1m 40s\n",
            "798:\tlearn: 0.0635043\ttotal: 6m 36s\tremaining: 1m 39s\n",
            "799:\tlearn: 0.0634810\ttotal: 6m 36s\tremaining: 1m 39s\n",
            "800:\tlearn: 0.0634667\ttotal: 6m 37s\tremaining: 1m 38s\n",
            "801:\tlearn: 0.0634438\ttotal: 6m 37s\tremaining: 1m 38s\n",
            "802:\tlearn: 0.0634111\ttotal: 6m 38s\tremaining: 1m 37s\n",
            "803:\tlearn: 0.0633757\ttotal: 6m 38s\tremaining: 1m 37s\n",
            "804:\tlearn: 0.0633622\ttotal: 6m 39s\tremaining: 1m 36s\n",
            "805:\tlearn: 0.0633477\ttotal: 6m 39s\tremaining: 1m 36s\n",
            "806:\tlearn: 0.0633269\ttotal: 6m 40s\tremaining: 1m 35s\n",
            "807:\tlearn: 0.0633198\ttotal: 6m 40s\tremaining: 1m 35s\n",
            "808:\tlearn: 0.0632976\ttotal: 6m 41s\tremaining: 1m 34s\n",
            "809:\tlearn: 0.0632900\ttotal: 6m 41s\tremaining: 1m 34s\n",
            "810:\tlearn: 0.0632680\ttotal: 6m 42s\tremaining: 1m 33s\n",
            "811:\tlearn: 0.0632603\ttotal: 6m 42s\tremaining: 1m 33s\n",
            "812:\tlearn: 0.0632399\ttotal: 6m 42s\tremaining: 1m 32s\n",
            "813:\tlearn: 0.0632227\ttotal: 6m 43s\tremaining: 1m 32s\n",
            "814:\tlearn: 0.0632065\ttotal: 6m 43s\tremaining: 1m 31s\n",
            "815:\tlearn: 0.0632009\ttotal: 6m 44s\tremaining: 1m 31s\n",
            "816:\tlearn: 0.0631900\ttotal: 6m 44s\tremaining: 1m 30s\n",
            "817:\tlearn: 0.0631680\ttotal: 6m 45s\tremaining: 1m 30s\n",
            "818:\tlearn: 0.0631521\ttotal: 6m 45s\tremaining: 1m 29s\n",
            "819:\tlearn: 0.0631218\ttotal: 6m 45s\tremaining: 1m 29s\n",
            "820:\tlearn: 0.0631028\ttotal: 6m 46s\tremaining: 1m 28s\n",
            "821:\tlearn: 0.0630990\ttotal: 6m 46s\tremaining: 1m 28s\n",
            "822:\tlearn: 0.0630806\ttotal: 6m 47s\tremaining: 1m 27s\n",
            "823:\tlearn: 0.0630685\ttotal: 6m 47s\tremaining: 1m 27s\n",
            "824:\tlearn: 0.0630512\ttotal: 6m 48s\tremaining: 1m 26s\n",
            "825:\tlearn: 0.0630422\ttotal: 6m 48s\tremaining: 1m 26s\n",
            "826:\tlearn: 0.0630205\ttotal: 6m 49s\tremaining: 1m 25s\n",
            "827:\tlearn: 0.0629813\ttotal: 6m 49s\tremaining: 1m 25s\n",
            "828:\tlearn: 0.0629807\ttotal: 6m 50s\tremaining: 1m 24s\n",
            "829:\tlearn: 0.0629462\ttotal: 6m 50s\tremaining: 1m 24s\n",
            "830:\tlearn: 0.0629410\ttotal: 6m 50s\tremaining: 1m 23s\n",
            "831:\tlearn: 0.0629304\ttotal: 6m 51s\tremaining: 1m 23s\n",
            "832:\tlearn: 0.0629006\ttotal: 6m 51s\tremaining: 1m 22s\n",
            "833:\tlearn: 0.0628840\ttotal: 6m 52s\tremaining: 1m 22s\n",
            "834:\tlearn: 0.0628808\ttotal: 6m 52s\tremaining: 1m 21s\n",
            "835:\tlearn: 0.0628614\ttotal: 6m 53s\tremaining: 1m 21s\n",
            "836:\tlearn: 0.0628389\ttotal: 6m 53s\tremaining: 1m 20s\n",
            "837:\tlearn: 0.0628149\ttotal: 6m 54s\tremaining: 1m 20s\n",
            "838:\tlearn: 0.0628051\ttotal: 6m 54s\tremaining: 1m 19s\n",
            "839:\tlearn: 0.0627962\ttotal: 6m 55s\tremaining: 1m 19s\n",
            "840:\tlearn: 0.0627883\ttotal: 6m 55s\tremaining: 1m 18s\n",
            "841:\tlearn: 0.0627765\ttotal: 6m 55s\tremaining: 1m 18s\n",
            "842:\tlearn: 0.0627303\ttotal: 6m 56s\tremaining: 1m 17s\n",
            "843:\tlearn: 0.0627201\ttotal: 6m 56s\tremaining: 1m 17s\n",
            "844:\tlearn: 0.0627021\ttotal: 6m 57s\tremaining: 1m 16s\n",
            "845:\tlearn: 0.0626943\ttotal: 6m 57s\tremaining: 1m 16s\n",
            "846:\tlearn: 0.0626851\ttotal: 6m 58s\tremaining: 1m 15s\n",
            "847:\tlearn: 0.0626699\ttotal: 6m 58s\tremaining: 1m 15s\n",
            "848:\tlearn: 0.0626529\ttotal: 6m 59s\tremaining: 1m 14s\n",
            "849:\tlearn: 0.0626155\ttotal: 6m 59s\tremaining: 1m 14s\n",
            "850:\tlearn: 0.0625980\ttotal: 7m\tremaining: 1m 13s\n",
            "851:\tlearn: 0.0625680\ttotal: 7m\tremaining: 1m 13s\n",
            "852:\tlearn: 0.0625532\ttotal: 7m 1s\tremaining: 1m 12s\n",
            "853:\tlearn: 0.0625357\ttotal: 7m 1s\tremaining: 1m 12s\n",
            "854:\tlearn: 0.0625282\ttotal: 7m 2s\tremaining: 1m 11s\n",
            "855:\tlearn: 0.0625239\ttotal: 7m 2s\tremaining: 1m 11s\n",
            "856:\tlearn: 0.0625008\ttotal: 7m 3s\tremaining: 1m 10s\n",
            "857:\tlearn: 0.0624668\ttotal: 7m 3s\tremaining: 1m 10s\n",
            "858:\tlearn: 0.0624652\ttotal: 7m 3s\tremaining: 1m 9s\n",
            "859:\tlearn: 0.0624420\ttotal: 7m 4s\tremaining: 1m 9s\n",
            "860:\tlearn: 0.0624248\ttotal: 7m 5s\tremaining: 1m 8s\n",
            "861:\tlearn: 0.0624116\ttotal: 7m 5s\tremaining: 1m 8s\n",
            "862:\tlearn: 0.0623928\ttotal: 7m 6s\tremaining: 1m 7s\n",
            "863:\tlearn: 0.0623754\ttotal: 7m 6s\tremaining: 1m 7s\n",
            "864:\tlearn: 0.0623421\ttotal: 7m 7s\tremaining: 1m 6s\n",
            "865:\tlearn: 0.0623243\ttotal: 7m 7s\tremaining: 1m 6s\n",
            "866:\tlearn: 0.0622972\ttotal: 7m 8s\tremaining: 1m 5s\n",
            "867:\tlearn: 0.0622752\ttotal: 7m 8s\tremaining: 1m 5s\n",
            "868:\tlearn: 0.0622184\ttotal: 7m 8s\tremaining: 1m 4s\n",
            "869:\tlearn: 0.0621874\ttotal: 7m 9s\tremaining: 1m 4s\n",
            "870:\tlearn: 0.0621741\ttotal: 7m 9s\tremaining: 1m 3s\n",
            "871:\tlearn: 0.0621581\ttotal: 7m 10s\tremaining: 1m 3s\n",
            "872:\tlearn: 0.0621307\ttotal: 7m 11s\tremaining: 1m 2s\n",
            "873:\tlearn: 0.0620985\ttotal: 7m 11s\tremaining: 1m 2s\n",
            "874:\tlearn: 0.0620847\ttotal: 7m 12s\tremaining: 1m 1s\n",
            "875:\tlearn: 0.0620468\ttotal: 7m 12s\tremaining: 1m 1s\n",
            "876:\tlearn: 0.0620344\ttotal: 7m 13s\tremaining: 1m\n",
            "877:\tlearn: 0.0620131\ttotal: 7m 13s\tremaining: 1m\n",
            "878:\tlearn: 0.0619668\ttotal: 7m 14s\tremaining: 59.8s\n",
            "879:\tlearn: 0.0619641\ttotal: 7m 14s\tremaining: 59.3s\n",
            "880:\tlearn: 0.0619573\ttotal: 7m 15s\tremaining: 58.8s\n",
            "881:\tlearn: 0.0619449\ttotal: 7m 15s\tremaining: 58.3s\n",
            "882:\tlearn: 0.0619254\ttotal: 7m 15s\tremaining: 57.8s\n",
            "883:\tlearn: 0.0619046\ttotal: 7m 16s\tremaining: 57.3s\n",
            "884:\tlearn: 0.0618967\ttotal: 7m 16s\tremaining: 56.7s\n",
            "885:\tlearn: 0.0618744\ttotal: 7m 17s\tremaining: 56.3s\n",
            "886:\tlearn: 0.0618436\ttotal: 7m 17s\tremaining: 55.8s\n",
            "887:\tlearn: 0.0618130\ttotal: 7m 18s\tremaining: 55.3s\n",
            "888:\tlearn: 0.0618045\ttotal: 7m 18s\tremaining: 54.8s\n",
            "889:\tlearn: 0.0617896\ttotal: 7m 19s\tremaining: 54.3s\n",
            "890:\tlearn: 0.0617823\ttotal: 7m 19s\tremaining: 53.8s\n",
            "891:\tlearn: 0.0617727\ttotal: 7m 20s\tremaining: 53.3s\n",
            "892:\tlearn: 0.0617530\ttotal: 7m 20s\tremaining: 52.8s\n",
            "893:\tlearn: 0.0617498\ttotal: 7m 21s\tremaining: 52.3s\n",
            "894:\tlearn: 0.0617319\ttotal: 7m 21s\tremaining: 51.8s\n",
            "895:\tlearn: 0.0617293\ttotal: 7m 21s\tremaining: 51.3s\n",
            "896:\tlearn: 0.0617140\ttotal: 7m 22s\tremaining: 50.8s\n",
            "897:\tlearn: 0.0616943\ttotal: 7m 22s\tremaining: 50.3s\n",
            "898:\tlearn: 0.0616791\ttotal: 7m 23s\tremaining: 49.8s\n",
            "899:\tlearn: 0.0616640\ttotal: 7m 23s\tremaining: 49.3s\n",
            "900:\tlearn: 0.0616366\ttotal: 7m 24s\tremaining: 48.8s\n",
            "901:\tlearn: 0.0616295\ttotal: 7m 24s\tremaining: 48.3s\n",
            "902:\tlearn: 0.0616241\ttotal: 7m 24s\tremaining: 47.8s\n",
            "903:\tlearn: 0.0615880\ttotal: 7m 25s\tremaining: 47.3s\n",
            "904:\tlearn: 0.0615836\ttotal: 7m 25s\tremaining: 46.8s\n",
            "905:\tlearn: 0.0615520\ttotal: 7m 26s\tremaining: 46.3s\n",
            "906:\tlearn: 0.0615363\ttotal: 7m 26s\tremaining: 45.8s\n",
            "907:\tlearn: 0.0615255\ttotal: 7m 27s\tremaining: 45.3s\n",
            "908:\tlearn: 0.0615132\ttotal: 7m 27s\tremaining: 44.8s\n",
            "909:\tlearn: 0.0614951\ttotal: 7m 28s\tremaining: 44.3s\n",
            "910:\tlearn: 0.0614775\ttotal: 7m 28s\tremaining: 43.8s\n",
            "911:\tlearn: 0.0614472\ttotal: 7m 29s\tremaining: 43.4s\n",
            "912:\tlearn: 0.0614151\ttotal: 7m 30s\tremaining: 42.9s\n",
            "913:\tlearn: 0.0614084\ttotal: 7m 30s\tremaining: 42.4s\n",
            "914:\tlearn: 0.0613973\ttotal: 7m 30s\tremaining: 41.9s\n",
            "915:\tlearn: 0.0613933\ttotal: 7m 31s\tremaining: 41.4s\n",
            "916:\tlearn: 0.0613692\ttotal: 7m 31s\tremaining: 40.9s\n",
            "917:\tlearn: 0.0613481\ttotal: 7m 32s\tremaining: 40.4s\n",
            "918:\tlearn: 0.0613350\ttotal: 7m 32s\tremaining: 39.9s\n",
            "919:\tlearn: 0.0613094\ttotal: 7m 33s\tremaining: 39.4s\n",
            "920:\tlearn: 0.0613020\ttotal: 7m 33s\tremaining: 38.9s\n",
            "921:\tlearn: 0.0612849\ttotal: 7m 34s\tremaining: 38.4s\n",
            "922:\tlearn: 0.0612355\ttotal: 7m 34s\tremaining: 37.9s\n",
            "923:\tlearn: 0.0612337\ttotal: 7m 35s\tremaining: 37.4s\n",
            "924:\tlearn: 0.0612272\ttotal: 7m 35s\tremaining: 36.9s\n",
            "925:\tlearn: 0.0612151\ttotal: 7m 35s\tremaining: 36.4s\n",
            "926:\tlearn: 0.0612044\ttotal: 7m 36s\tremaining: 35.9s\n",
            "927:\tlearn: 0.0611955\ttotal: 7m 36s\tremaining: 35.4s\n",
            "928:\tlearn: 0.0611805\ttotal: 7m 37s\tremaining: 34.9s\n",
            "929:\tlearn: 0.0611556\ttotal: 7m 37s\tremaining: 34.4s\n",
            "930:\tlearn: 0.0611436\ttotal: 7m 38s\tremaining: 34s\n",
            "931:\tlearn: 0.0611231\ttotal: 7m 38s\tremaining: 33.5s\n",
            "932:\tlearn: 0.0611206\ttotal: 7m 38s\tremaining: 33s\n",
            "933:\tlearn: 0.0611014\ttotal: 7m 39s\tremaining: 32.5s\n",
            "934:\tlearn: 0.0610883\ttotal: 7m 39s\tremaining: 32s\n",
            "935:\tlearn: 0.0610844\ttotal: 7m 40s\tremaining: 31.5s\n",
            "936:\tlearn: 0.0610621\ttotal: 7m 40s\tremaining: 31s\n",
            "937:\tlearn: 0.0610514\ttotal: 7m 41s\tremaining: 30.5s\n",
            "938:\tlearn: 0.0610467\ttotal: 7m 41s\tremaining: 30s\n",
            "939:\tlearn: 0.0610461\ttotal: 7m 41s\tremaining: 29.5s\n",
            "940:\tlearn: 0.0610395\ttotal: 7m 42s\tremaining: 29s\n",
            "941:\tlearn: 0.0610234\ttotal: 7m 43s\tremaining: 28.5s\n",
            "942:\tlearn: 0.0610190\ttotal: 7m 43s\tremaining: 28s\n",
            "943:\tlearn: 0.0610070\ttotal: 7m 43s\tremaining: 27.5s\n",
            "944:\tlearn: 0.0610011\ttotal: 7m 44s\tremaining: 27s\n",
            "945:\tlearn: 0.0609872\ttotal: 7m 44s\tremaining: 26.5s\n",
            "946:\tlearn: 0.0609671\ttotal: 7m 45s\tremaining: 26s\n",
            "947:\tlearn: 0.0609513\ttotal: 7m 45s\tremaining: 25.5s\n",
            "948:\tlearn: 0.0609375\ttotal: 7m 46s\tremaining: 25s\n",
            "949:\tlearn: 0.0609277\ttotal: 7m 46s\tremaining: 24.6s\n",
            "950:\tlearn: 0.0609187\ttotal: 7m 46s\tremaining: 24.1s\n",
            "951:\tlearn: 0.0609077\ttotal: 7m 47s\tremaining: 23.6s\n",
            "952:\tlearn: 0.0608884\ttotal: 7m 47s\tremaining: 23.1s\n",
            "953:\tlearn: 0.0608716\ttotal: 7m 48s\tremaining: 22.6s\n",
            "954:\tlearn: 0.0608508\ttotal: 7m 48s\tremaining: 22.1s\n",
            "955:\tlearn: 0.0608288\ttotal: 7m 49s\tremaining: 21.6s\n",
            "956:\tlearn: 0.0608189\ttotal: 7m 49s\tremaining: 21.1s\n",
            "957:\tlearn: 0.0608106\ttotal: 7m 50s\tremaining: 20.6s\n",
            "958:\tlearn: 0.0607946\ttotal: 7m 50s\tremaining: 20.1s\n",
            "959:\tlearn: 0.0607911\ttotal: 7m 50s\tremaining: 19.6s\n",
            "960:\tlearn: 0.0607805\ttotal: 7m 51s\tremaining: 19.1s\n",
            "961:\tlearn: 0.0607723\ttotal: 7m 51s\tremaining: 18.6s\n",
            "962:\tlearn: 0.0607507\ttotal: 7m 52s\tremaining: 18.1s\n",
            "963:\tlearn: 0.0607396\ttotal: 7m 52s\tremaining: 17.7s\n",
            "964:\tlearn: 0.0606944\ttotal: 7m 53s\tremaining: 17.2s\n",
            "965:\tlearn: 0.0606840\ttotal: 7m 53s\tremaining: 16.7s\n",
            "966:\tlearn: 0.0606656\ttotal: 7m 54s\tremaining: 16.2s\n",
            "967:\tlearn: 0.0606486\ttotal: 7m 54s\tremaining: 15.7s\n",
            "968:\tlearn: 0.0606095\ttotal: 7m 55s\tremaining: 15.2s\n",
            "969:\tlearn: 0.0605712\ttotal: 7m 55s\tremaining: 14.7s\n",
            "970:\tlearn: 0.0605573\ttotal: 7m 56s\tremaining: 14.2s\n",
            "971:\tlearn: 0.0605308\ttotal: 7m 56s\tremaining: 13.7s\n",
            "972:\tlearn: 0.0605130\ttotal: 7m 57s\tremaining: 13.2s\n",
            "973:\tlearn: 0.0604806\ttotal: 7m 57s\tremaining: 12.8s\n",
            "974:\tlearn: 0.0604646\ttotal: 7m 58s\tremaining: 12.3s\n",
            "975:\tlearn: 0.0604496\ttotal: 7m 58s\tremaining: 11.8s\n",
            "976:\tlearn: 0.0604241\ttotal: 7m 59s\tremaining: 11.3s\n",
            "977:\tlearn: 0.0603694\ttotal: 7m 59s\tremaining: 10.8s\n",
            "978:\tlearn: 0.0603614\ttotal: 8m\tremaining: 10.3s\n",
            "979:\tlearn: 0.0603510\ttotal: 8m\tremaining: 9.81s\n",
            "980:\tlearn: 0.0603423\ttotal: 8m 1s\tremaining: 9.32s\n",
            "981:\tlearn: 0.0603240\ttotal: 8m 1s\tremaining: 8.83s\n",
            "982:\tlearn: 0.0603068\ttotal: 8m 2s\tremaining: 8.34s\n",
            "983:\tlearn: 0.0602901\ttotal: 8m 2s\tremaining: 7.85s\n",
            "984:\tlearn: 0.0602635\ttotal: 8m 3s\tremaining: 7.36s\n",
            "985:\tlearn: 0.0602390\ttotal: 8m 3s\tremaining: 6.87s\n",
            "986:\tlearn: 0.0602208\ttotal: 8m 4s\tremaining: 6.38s\n",
            "987:\tlearn: 0.0602140\ttotal: 8m 4s\tremaining: 5.89s\n",
            "988:\tlearn: 0.0601898\ttotal: 8m 5s\tremaining: 5.4s\n",
            "989:\tlearn: 0.0601826\ttotal: 8m 5s\tremaining: 4.91s\n",
            "990:\tlearn: 0.0601761\ttotal: 8m 5s\tremaining: 4.41s\n",
            "991:\tlearn: 0.0601745\ttotal: 8m 6s\tremaining: 3.92s\n",
            "992:\tlearn: 0.0601694\ttotal: 8m 6s\tremaining: 3.43s\n",
            "993:\tlearn: 0.0601545\ttotal: 8m 7s\tremaining: 2.94s\n",
            "994:\tlearn: 0.0601446\ttotal: 8m 7s\tremaining: 2.45s\n",
            "995:\tlearn: 0.0601217\ttotal: 8m 8s\tremaining: 1.96s\n",
            "996:\tlearn: 0.0601130\ttotal: 8m 8s\tremaining: 1.47s\n",
            "997:\tlearn: 0.0601017\ttotal: 8m 9s\tremaining: 980ms\n",
            "998:\tlearn: 0.0600712\ttotal: 8m 9s\tremaining: 490ms\n",
            "999:\tlearn: 0.0600381\ttotal: 8m 10s\tremaining: 0us\n",
            "0.9573968393984447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{roc_auc_score(y_pred, y_val)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtCm9PSbRXT_",
        "outputId": "b6ba9382-1ffa-4a08-d67a-151296850fd2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9573968393984447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тестовые данные"
      ],
      "metadata": {
        "id": "VgW_omwkS97N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test, df_y1 = get_data('gdrive/My Drive/data/gp2/test_transaction.csv', \n",
        "                'gdrive/My Drive/data/gp2/test_identity.csv',\n",
        "                True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaHwtX_nTFrm",
        "outputId": "2e7370a4-f568-45f0-84d6-3d2b3d5ae368"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_col = {}\n",
        "for column in df_test.columns:\n",
        "  if column.startswith('id-'):\n",
        "    dict_col[column] = column.replace(\"-\",\"_\")\n",
        "df_test.rename(columns = dict_col,inplace=True)   "
      ],
      "metadata": {
        "id": "es_zrtkwnDbX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_test[column_dict['float_column']+column_dict['numeric_column']+\\\n",
        "                  column_dict['categorical_column']]"
      ],
      "metadata": {
        "id": "6XVd1PjypHnB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test,column_dict = fill_data(df_test,column_dict,is_drop_nan_columns, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDfeeEwVTDpn",
        "outputId": "29613ed7-022e-4bb4-f5b3-8bbd2199f8fb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:6392: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return self._update_inplace(result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if is_need_pca == True:\n",
        "  X_test_pca_part = pca.transform(df_test[column_dict['float_column']+column_dict['numeric_column']])\n",
        "  Y_test_pred = model.predict(X_test_pca_part)\n",
        "else:\n",
        "  Y_test_pred = model.predict(df_test[column_dict['float_column']+column_dict['numeric_column']])\n",
        "submission = pd.DataFrame(columns=['TransactionID'], data=df_y1 )\n",
        "submission[target] = Y_test_pred\n",
        "submission.head()\n",
        "submission.isFraud.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZANKXj37dGOu",
        "outputId": "0c4de5ae-2c64-4cf9-d16f-1e7f47939c80"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    499502\n",
              "1      7189\n",
              "Name: isFraud, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"submission.csv\", index = False)"
      ],
      "metadata": {
        "id": "W-Xw3RGihy9g"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"train_pool = catboost.Pool(\n",
        "    X_train,\n",
        "    label=y_train,\n",
        "    cat_features=f\n",
        ")\n",
        "val_pool = catboost.Pool(\n",
        "    X_validate,\n",
        "    label=y_validate,\n",
        "    cat_features=f\n",
        ")\n",
        "test_pool = catboost.Pool(\n",
        "    X_test,\n",
        "    cat_features=f\n",
        ")\"\"\""
      ],
      "metadata": {
        "id": "ihbRp-XRN_uq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}